{
  "evaluation": {
    "episode_reward_max": 65.0,
    "episode_reward_min": -78.0,
    "episode_reward_mean": 5.6,
    "episode_len_mean": 76.0,
    "episode_media": {},
    "episodes_this_iter": 10,
    "policy_reward_min": {},
    "policy_reward_max": {},
    "policy_reward_mean": {},
    "custom_metrics": {},
    "hist_stats": {
      "episode_reward": [
        -56.0,
        -78.0,
        21.0,
        32.0,
        -45.0,
        10.0,
        65.0,
        54.0,
        32.0,
        21.0
      ],
      "episode_lengths": [
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76
      ]
    },
    "sampler_perf": {
      "mean_raw_obs_processing_ms": 0.17801628162920397,
      "mean_inference_ms": 9.149628149225581,
      "mean_action_processing_ms": 0.08046454731644218,
      "mean_env_wait_ms": 0.04096350751317911,
      "mean_env_render_ms": 0.0
    },
    "num_faulty_episodes": 0,
    "connector_metrics": {
      "ObsPreprocessorConnector_ms": 0.004961490631103516,
      "StateBufferConnector_ms": 0.003006458282470703,
      "ViewRequirementAgentConnector_ms": 0.08241415023803711
    },
    "num_agent_steps_sampled_this_iter": 760,
    "num_env_steps_sampled_this_iter": 760,
    "timesteps_this_iter": 760,
    "num_healthy_workers": 1,
    "num_in_flight_async_reqs": 0,
    "num_remote_worker_restarts": 0
  },
  "custom_metrics": {},
  "episode_media": {},
  "info": {
    "learner": {
      "default_policy": {
        "learner_stats": {
          "cur_kl_coeff": 0.20000000298023224,
          "cur_lr": 0.0010000000474974513,
          "total_loss": 7.921999454498291,
          "policy_loss": -0.02222762443125248,
          "vf_loss": 7.9402241706848145,
          "vf_explained_var": -0.004099844954907894,
          "kl": 0.020017357543110847,
          "entropy": 2.9758834838867188,
          "entropy_coeff": 0.0
        },
        "custom_metrics": {},
        "num_agent_steps_trained": 125.0,
        "num_grad_updates_lifetime": 480.5,
        "diff_num_grad_updates_vs_sampler_policy": 479.5
      }
    },
    "num_env_steps_sampled": 4000,
    "num_env_steps_trained": 4000,
    "num_agent_steps_sampled": 4000,
    "num_agent_steps_trained": 4000
  },
  "sampler_results": {
    "episode_reward_max": 76.0,
    "episode_reward_min": -78.0,
    "episode_reward_mean": 6.1923076923076925,
    "episode_len_mean": 76.0,
    "episode_media": {},
    "episodes_this_iter": 52,
    "policy_reward_min": {},
    "policy_reward_max": {},
    "policy_reward_mean": {},
    "custom_metrics": {},
    "hist_stats": {
      "episode_reward": [
        -78.0,
        -12.0,
        -1.0,
        21.0,
        -12.0,
        21.0,
        32.0,
        21.0,
        -23.0,
        43.0,
        -12.0,
        54.0,
        -78.0,
        -34.0,
        32.0,
        21.0,
        76.0,
        43.0,
        32.0,
        54.0,
        -67.0,
        -78.0,
        21.0,
        43.0,
        10.0,
        -23.0,
        -56.0,
        -23.0,
        43.0,
        -12.0,
        -23.0,
        -1.0,
        -45.0,
        -12.0,
        -1.0,
        -1.0,
        65.0,
        54.0,
        21.0,
        21.0,
        -12.0,
        32.0,
        -34.0,
        -56.0,
        43.0,
        -1.0,
        54.0,
        10.0,
        76.0,
        -23.0,
        32.0,
        65.0
      ],
      "episode_lengths": [
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76
      ]
    },
    "sampler_perf": {
      "mean_raw_obs_processing_ms": 0.17695342323476748,
      "mean_inference_ms": 9.210601266519157,
      "mean_action_processing_ms": 0.07327125537875173,
      "mean_env_wait_ms": 0.034909163734609554,
      "mean_env_render_ms": 0.0
    },
    "num_faulty_episodes": 0,
    "connector_metrics": {
      "ObsPreprocessorConnector_ms": 0.0042525621560903695,
      "StateBufferConnector_ms": 0.002660201146052434,
      "ViewRequirementAgentConnector_ms": 0.07656491719759427
    }
  },
  "episode_reward_max": 76.0,
  "episode_reward_min": -78.0,
  "episode_reward_mean": 6.1923076923076925,
  "episode_len_mean": 76.0,
  "episodes_this_iter": 52,
  "policy_reward_min": {},
  "policy_reward_max": {},
  "policy_reward_mean": {},
  "hist_stats": {
    "episode_reward": [
      -78.0,
      -12.0,
      -1.0,
      21.0,
      -12.0,
      21.0,
      32.0,
      21.0,
      -23.0,
      43.0,
      -12.0,
      54.0,
      -78.0,
      -34.0,
      32.0,
      21.0,
      76.0,
      43.0,
      32.0,
      54.0,
      -67.0,
      -78.0,
      21.0,
      43.0,
      10.0,
      -23.0,
      -56.0,
      -23.0,
      43.0,
      -12.0,
      -23.0,
      -1.0,
      -45.0,
      -12.0,
      -1.0,
      -1.0,
      65.0,
      54.0,
      21.0,
      21.0,
      -12.0,
      32.0,
      -34.0,
      -56.0,
      43.0,
      -1.0,
      54.0,
      10.0,
      76.0,
      -23.0,
      32.0,
      65.0
    ],
    "episode_lengths": [
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76
    ]
  },
  "sampler_perf": {
    "mean_raw_obs_processing_ms": 0.17695342323476748,
    "mean_inference_ms": 9.210601266519157,
    "mean_action_processing_ms": 0.07327125537875173,
    "mean_env_wait_ms": 0.034909163734609554,
    "mean_env_render_ms": 0.0
  },
  "num_faulty_episodes": 0,
  "connector_metrics": {
    "ObsPreprocessorConnector_ms": 0.0042525621560903695,
    "StateBufferConnector_ms": 0.002660201146052434,
    "ViewRequirementAgentConnector_ms": 0.07656491719759427
  },
  "num_healthy_workers": 1,
  "num_in_flight_async_reqs": 0,
  "num_remote_worker_restarts": 0,
  "num_agent_steps_sampled": 4000,
  "num_agent_steps_trained": 4000,
  "num_env_steps_sampled": 4000,
  "num_env_steps_trained": 4000,
  "num_env_steps_sampled_this_iter": 4000,
  "num_env_steps_trained_this_iter": 4000,
  "timesteps_total": 4000,
  "num_steps_trained_this_iter": 4000,
  "agent_timesteps_total": 4000,
  "timers": {
    "training_iteration_time_ms": 71876.84,
    "sample_time_ms": 38030.404,
    "learn_time_ms": 33837.324,
    "learn_throughput": 118.213,
    "synch_weights_time_ms": 7.151
  },
  "counters": {
    "num_env_steps_sampled": 4000,
    "num_env_steps_trained": 4000,
    "num_agent_steps_sampled": 4000,
    "num_agent_steps_trained": 4000
  },
  "done": false,
  "episodes_total": 52,
  "training_iteration": 1,
  "trial_id": "b0a0c_00000",
  "date": "2023-05-31_15-44-40",
  "timestamp": 1685537080,
  "time_this_iter_s": 79.12273693084717,
  "time_total_s": 79.12273693084717,
  "pid": 48728,
  "hostname": "Ozans-MacBook-Pro.local",
  "node_ip": "127.0.0.1",
  "config": {
    "extra_python_environs_for_driver": {},
    "extra_python_environs_for_worker": {},
    "num_gpus": 0,
    "num_cpus_per_worker": 1,
    "num_gpus_per_worker": 0,
    "_fake_gpus": false,
    "num_learner_workers": 0,
    "num_gpus_per_learner_worker": 0,
    "num_cpus_per_learner_worker": 1,
    "local_gpu_idx": 0,
    "custom_resources_per_worker": {},
    "placement_strategy": "PACK",
    "eager_tracing": false,
    "eager_max_retraces": 20,
    "tf_session_args": {
      "intra_op_parallelism_threads": 2,
      "inter_op_parallelism_threads": 2,
      "gpu_options": {
        "allow_growth": true
      },
      "log_device_placement": false,
      "device_count": {
        "CPU": 1
      },
      "allow_soft_placement": true
    },
    "local_tf_session_args": {
      "intra_op_parallelism_threads": 8,
      "inter_op_parallelism_threads": 8
    },
    "env": "Supermarket",
    "env_config": {},
    "observation_space": null,
    "action_space": null,
    "env_task_fn": null,
    "render_env": false,
    "clip_rewards": null,
    "normalize_actions": true,
    "clip_actions": false,
    "disable_env_checking": false,
    "is_atari": false,
    "auto_wrap_old_gym_envs": true,
    "num_envs_per_worker": 1,
    "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>",
    "sample_async": false,
    "enable_connectors": true,
    "rollout_fragment_length": "auto",
    "batch_mode": "truncate_episodes",
    "remote_worker_envs": false,
    "remote_env_batch_wait_ms": 0,
    "validate_workers_after_construction": true,
    "preprocessor_pref": "deepmind",
    "observation_filter": "NoFilter",
    "synchronize_filters": true,
    "compress_observations": false,
    "enable_tf1_exec_eagerly": false,
    "sampler_perf_stats_ema_coef": null,
    "gamma": 0.9,
    "lr": 0.001,
    "train_batch_size": 4000,
    "model": {
      "_disable_preprocessor_api": false,
      "_disable_action_flattening": false,
      "fcnet_hiddens": [
        4,
        4
      ],
      "fcnet_activation": "tanh",
      "conv_filters": null,
      "conv_activation": "relu",
      "post_fcnet_hiddens": [],
      "post_fcnet_activation": "relu",
      "free_log_std": false,
      "no_final_linear": false,
      "vf_share_layers": false,
      "use_lstm": false,
      "max_seq_len": 20,
      "lstm_cell_size": 256,
      "lstm_use_prev_action": false,
      "lstm_use_prev_reward": false,
      "_time_major": false,
      "use_attention": false,
      "attention_num_transformer_units": 1,
      "attention_dim": 64,
      "attention_num_heads": 1,
      "attention_head_dim": 32,
      "attention_memory_inference": 50,
      "attention_memory_training": 50,
      "attention_position_wise_mlp_dim": 32,
      "attention_init_gru_gate_bias": 2.0,
      "attention_use_n_prev_actions": 0,
      "attention_use_n_prev_rewards": 0,
      "framestack": true,
      "dim": 84,
      "grayscale": false,
      "zero_mean": true,
      "custom_model": null,
      "custom_model_config": {},
      "custom_action_dist": null,
      "custom_preprocessor": null,
      "encoder_latent_dim": null,
      "lstm_use_prev_action_reward": -1,
      "_use_default_native_models": -1
    },
    "optimizer": {},
    "max_requests_in_flight_per_sampler_worker": 2,
    "learner_class": null,
    "_enable_learner_api": false,
    "_learner_hps": "PPOLearnerHPs(kl_coeff=0.2, kl_target=0.01, use_critic=True, clip_param=0.3, vf_clip_param=10.0, entropy_coeff=0.0, vf_loss_coeff=1.0, lr_schedule=None, entropy_coeff_schedule=None)",
    "explore": true,
    "exploration_config": {
      "type": "StochasticSampling"
    },
    "policy_states_are_swappable": false,
    "input_config": {},
    "actions_in_input_normalized": false,
    "postprocess_inputs": false,
    "shuffle_buffer_size": 0,
    "output": null,
    "output_config": {},
    "output_compress_columns": [
      "obs",
      "new_obs"
    ],
    "output_max_file_size": 67108864,
    "offline_sampling": false,
    "evaluation_interval": 1,
    "evaluation_duration": 10,
    "evaluation_duration_unit": "episodes",
    "evaluation_sample_timeout_s": 180.0,
    "evaluation_parallel_to_training": false,
    "evaluation_config": null,
    "off_policy_estimation_methods": {},
    "ope_split_batch_by_episode": true,
    "evaluation_num_workers": 1,
    "always_attach_evaluation_results": false,
    "enable_async_evaluation": false,
    "in_evaluation": false,
    "sync_filters_on_rollout_workers_timeout_s": 60.0,
    "keep_per_episode_custom_metrics": false,
    "metrics_episode_collection_timeout_s": 60.0,
    "metrics_num_episodes_for_smoothing": 100,
    "min_time_s_per_iteration": null,
    "min_train_timesteps_per_iteration": 0,
    "min_sample_timesteps_per_iteration": 0,
    "export_native_model_files": false,
    "checkpoint_trainable_policies_only": false,
    "logger_creator": null,
    "logger_config": null,
    "log_level": "WARN",
    "log_sys_usage": true,
    "fake_sampler": false,
    "seed": null,
    "worker_cls": null,
    "ignore_worker_failures": false,
    "recreate_failed_workers": false,
    "max_num_worker_restarts": 1000,
    "delay_between_worker_restarts_s": 60.0,
    "restart_failed_sub_environments": false,
    "num_consecutive_worker_failures_tolerance": 100,
    "worker_health_probe_timeout_s": 60,
    "worker_restore_timeout_s": 1800,
    "rl_module_spec": null,
    "_enable_rl_module_api": false,
    "_validate_exploration_conf_and_rl_modules": true,
    "_tf_policy_handles_more_than_one_loss": false,
    "_disable_preprocessor_api": false,
    "_disable_action_flattening": false,
    "_disable_execution_plan_api": true,
    "simple_optimizer": true,
    "replay_sequence_length": null,
    "horizon": -1,
    "soft_horizon": -1,
    "no_done_at_end": -1,
    "lr_schedule": null,
    "use_critic": true,
    "use_gae": true,
    "kl_coeff": 0.2,
    "sgd_minibatch_size": 128,
    "num_sgd_iter": 30,
    "shuffle_sequences": true,
    "vf_loss_coeff": 1.0,
    "entropy_coeff": 0.0,
    "entropy_coeff_schedule": null,
    "clip_param": 0.3,
    "vf_clip_param": 10.0,
    "grad_clip": null,
    "kl_target": 0.01,
    "vf_share_layers": -1,
    "__stdout_file__": null,
    "__stderr_file__": null,
    "lambda": 1.0,
    "input": "sampler",
    "multiagent": {
      "policies": {
        "default_policy": [
          null,
          null,
          null,
          null
        ]
      },
      "policy_mapping_fn": "<function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x28f7c7ac0>",
      "policies_to_train": null,
      "policy_map_capacity": 100,
      "policy_map_cache": -1,
      "count_steps_by": "env_steps",
      "observation_fn": null
    },
    "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>",
    "create_env_on_driver": false,
    "custom_eval_function": null,
    "framework": "tf2",
    "num_cpus_for_driver": 1,
    "num_workers": 1
  },
  "time_since_restore": 79.12273693084717,
  "iterations_since_restore": 1,
  "perf": {
    "cpu_util_percent": 42.718918918918924,
    "ram_util_percent": 72.48918918918918
  }
}
{
  "evaluation": {
    "episode_reward_max": 21.0,
    "episode_reward_min": -67.0,
    "episode_reward_mean": -16.4,
    "episode_len_mean": 76.0,
    "episode_media": {},
    "episodes_this_iter": 10,
    "policy_reward_min": {},
    "policy_reward_max": {},
    "policy_reward_mean": {},
    "custom_metrics": {},
    "hist_stats": {
      "episode_reward": [
        21.0,
        -12.0,
        10.0,
        21.0,
        -67.0,
        -67.0,
        -12.0,
        -23.0,
        -45.0,
        10.0
      ],
      "episode_lengths": [
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76
      ]
    },
    "sampler_perf": {
      "mean_raw_obs_processing_ms": 0.17726962147850017,
      "mean_inference_ms": 9.244544658121665,
      "mean_action_processing_ms": 0.08063783463798488,
      "mean_env_wait_ms": 0.040718789636736086,
      "mean_env_render_ms": 0.0
    },
    "num_faulty_episodes": 0,
    "connector_metrics": {
      "ObsPreprocessorConnector_ms": 0.005240440368652344,
      "StateBufferConnector_ms": 0.003020763397216797,
      "ViewRequirementAgentConnector_ms": 0.08460044860839844
    },
    "num_agent_steps_sampled_this_iter": 760,
    "num_env_steps_sampled_this_iter": 760,
    "timesteps_this_iter": 760,
    "num_healthy_workers": 1,
    "num_in_flight_async_reqs": 0,
    "num_remote_worker_restarts": 0
  },
  "custom_metrics": {},
  "episode_media": {},
  "info": {
    "learner": {
      "default_policy": {
        "learner_stats": {
          "cur_kl_coeff": 0.30000001192092896,
          "cur_lr": 0.0010000000474974513,
          "total_loss": 7.685706615447998,
          "policy_loss": -0.014726049266755581,
          "vf_loss": 7.694891452789307,
          "vf_explained_var": 0.0023411025758832693,
          "kl": 0.01847066916525364,
          "entropy": 2.959333658218384,
          "entropy_coeff": 0.0
        },
        "custom_metrics": {},
        "num_agent_steps_trained": 125.0,
        "num_grad_updates_lifetime": 1440.5,
        "diff_num_grad_updates_vs_sampler_policy": 479.5
      }
    },
    "num_env_steps_sampled": 8000,
    "num_env_steps_trained": 8000,
    "num_agent_steps_sampled": 8000,
    "num_agent_steps_trained": 8000
  },
  "sampler_results": {
    "episode_reward_max": 76.0,
    "episode_reward_min": -89.0,
    "episode_reward_mean": 11.54,
    "episode_len_mean": 76.0,
    "episode_media": {},
    "episodes_this_iter": 53,
    "policy_reward_min": {},
    "policy_reward_max": {},
    "policy_reward_mean": {},
    "custom_metrics": {},
    "hist_stats": {
      "episode_reward": [
        21.0,
        32.0,
        21.0,
        -23.0,
        43.0,
        -12.0,
        54.0,
        -78.0,
        -34.0,
        32.0,
        21.0,
        76.0,
        43.0,
        32.0,
        54.0,
        -67.0,
        -78.0,
        21.0,
        43.0,
        10.0,
        -23.0,
        -56.0,
        -23.0,
        43.0,
        -12.0,
        -23.0,
        -1.0,
        -45.0,
        -12.0,
        -1.0,
        -1.0,
        65.0,
        54.0,
        21.0,
        21.0,
        -12.0,
        32.0,
        -34.0,
        -56.0,
        43.0,
        -1.0,
        54.0,
        10.0,
        76.0,
        -23.0,
        32.0,
        65.0,
        54.0,
        21.0,
        76.0,
        43.0,
        21.0,
        -1.0,
        -1.0,
        -34.0,
        21.0,
        21.0,
        32.0,
        -78.0,
        -1.0,
        21.0,
        -12.0,
        21.0,
        43.0,
        32.0,
        -89.0,
        32.0,
        -34.0,
        -23.0,
        54.0,
        -1.0,
        21.0,
        -12.0,
        -34.0,
        21.0,
        43.0,
        54.0,
        32.0,
        43.0,
        10.0,
        -45.0,
        32.0,
        76.0,
        21.0,
        43.0,
        -23.0,
        32.0,
        10.0,
        -1.0,
        -1.0,
        -1.0,
        10.0,
        21.0,
        -56.0,
        10.0,
        32.0,
        32.0,
        65.0,
        32.0,
        65.0
      ],
      "episode_lengths": [
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76
      ]
    },
    "sampler_perf": {
      "mean_raw_obs_processing_ms": 0.18057003474381803,
      "mean_inference_ms": 9.24249278028448,
      "mean_action_processing_ms": 0.07493959692855688,
      "mean_env_wait_ms": 0.035706398167554984,
      "mean_env_render_ms": 0.0
    },
    "num_faulty_episodes": 0,
    "connector_metrics": {
      "ObsPreprocessorConnector_ms": 0.004296779632568359,
      "StateBufferConnector_ms": 0.0027170181274414062,
      "ViewRequirementAgentConnector_ms": 0.08050680160522461
    }
  },
  "episode_reward_max": 76.0,
  "episode_reward_min": -89.0,
  "episode_reward_mean": 11.54,
  "episode_len_mean": 76.0,
  "episodes_this_iter": 53,
  "policy_reward_min": {},
  "policy_reward_max": {},
  "policy_reward_mean": {},
  "hist_stats": {
    "episode_reward": [
      21.0,
      32.0,
      21.0,
      -23.0,
      43.0,
      -12.0,
      54.0,
      -78.0,
      -34.0,
      32.0,
      21.0,
      76.0,
      43.0,
      32.0,
      54.0,
      -67.0,
      -78.0,
      21.0,
      43.0,
      10.0,
      -23.0,
      -56.0,
      -23.0,
      43.0,
      -12.0,
      -23.0,
      -1.0,
      -45.0,
      -12.0,
      -1.0,
      -1.0,
      65.0,
      54.0,
      21.0,
      21.0,
      -12.0,
      32.0,
      -34.0,
      -56.0,
      43.0,
      -1.0,
      54.0,
      10.0,
      76.0,
      -23.0,
      32.0,
      65.0,
      54.0,
      21.0,
      76.0,
      43.0,
      21.0,
      -1.0,
      -1.0,
      -34.0,
      21.0,
      21.0,
      32.0,
      -78.0,
      -1.0,
      21.0,
      -12.0,
      21.0,
      43.0,
      32.0,
      -89.0,
      32.0,
      -34.0,
      -23.0,
      54.0,
      -1.0,
      21.0,
      -12.0,
      -34.0,
      21.0,
      43.0,
      54.0,
      32.0,
      43.0,
      10.0,
      -45.0,
      32.0,
      76.0,
      21.0,
      43.0,
      -23.0,
      32.0,
      10.0,
      -1.0,
      -1.0,
      -1.0,
      10.0,
      21.0,
      -56.0,
      10.0,
      32.0,
      32.0,
      65.0,
      32.0,
      65.0
    ],
    "episode_lengths": [
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76
    ]
  },
  "sampler_perf": {
    "mean_raw_obs_processing_ms": 0.18057003474381803,
    "mean_inference_ms": 9.24249278028448,
    "mean_action_processing_ms": 0.07493959692855688,
    "mean_env_wait_ms": 0.035706398167554984,
    "mean_env_render_ms": 0.0
  },
  "num_faulty_episodes": 0,
  "connector_metrics": {
    "ObsPreprocessorConnector_ms": 0.004296779632568359,
    "StateBufferConnector_ms": 0.0027170181274414062,
    "ViewRequirementAgentConnector_ms": 0.08050680160522461
  },
  "num_healthy_workers": 1,
  "num_in_flight_async_reqs": 0,
  "num_remote_worker_restarts": 0,
  "num_agent_steps_sampled": 8000,
  "num_agent_steps_trained": 8000,
  "num_env_steps_sampled": 8000,
  "num_env_steps_trained": 8000,
  "num_env_steps_sampled_this_iter": 4000,
  "num_env_steps_trained_this_iter": 4000,
  "timesteps_total": 8000,
  "num_steps_trained_this_iter": 4000,
  "agent_timesteps_total": 8000,
  "timers": {
    "training_iteration_time_ms": 72147.866,
    "sample_time_ms": 38312.5,
    "learn_time_ms": 33827.041,
    "learn_throughput": 118.249,
    "synch_weights_time_ms": 7.072
  },
  "counters": {
    "num_env_steps_sampled": 8000,
    "num_env_steps_trained": 8000,
    "num_agent_steps_sampled": 8000,
    "num_agent_steps_trained": 8000
  },
  "done": false,
  "episodes_total": 105,
  "training_iteration": 2,
  "trial_id": "b0a0c_00000",
  "date": "2023-05-31_15-46-00",
  "timestamp": 1685537160,
  "time_this_iter_s": 79.7986991405487,
  "time_total_s": 158.92143607139587,
  "pid": 48728,
  "hostname": "Ozans-MacBook-Pro.local",
  "node_ip": "127.0.0.1",
  "config": {
    "extra_python_environs_for_driver": {},
    "extra_python_environs_for_worker": {},
    "num_gpus": 0,
    "num_cpus_per_worker": 1,
    "num_gpus_per_worker": 0,
    "_fake_gpus": false,
    "num_learner_workers": 0,
    "num_gpus_per_learner_worker": 0,
    "num_cpus_per_learner_worker": 1,
    "local_gpu_idx": 0,
    "custom_resources_per_worker": {},
    "placement_strategy": "PACK",
    "eager_tracing": false,
    "eager_max_retraces": 20,
    "tf_session_args": {
      "intra_op_parallelism_threads": 2,
      "inter_op_parallelism_threads": 2,
      "gpu_options": {
        "allow_growth": true
      },
      "log_device_placement": false,
      "device_count": {
        "CPU": 1
      },
      "allow_soft_placement": true
    },
    "local_tf_session_args": {
      "intra_op_parallelism_threads": 8,
      "inter_op_parallelism_threads": 8
    },
    "env": "Supermarket",
    "env_config": {},
    "observation_space": null,
    "action_space": null,
    "env_task_fn": null,
    "render_env": false,
    "clip_rewards": null,
    "normalize_actions": true,
    "clip_actions": false,
    "disable_env_checking": false,
    "is_atari": false,
    "auto_wrap_old_gym_envs": true,
    "num_envs_per_worker": 1,
    "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>",
    "sample_async": false,
    "enable_connectors": true,
    "rollout_fragment_length": "auto",
    "batch_mode": "truncate_episodes",
    "remote_worker_envs": false,
    "remote_env_batch_wait_ms": 0,
    "validate_workers_after_construction": true,
    "preprocessor_pref": "deepmind",
    "observation_filter": "NoFilter",
    "synchronize_filters": true,
    "compress_observations": false,
    "enable_tf1_exec_eagerly": false,
    "sampler_perf_stats_ema_coef": null,
    "gamma": 0.9,
    "lr": 0.001,
    "train_batch_size": 4000,
    "model": {
      "_disable_preprocessor_api": false,
      "_disable_action_flattening": false,
      "fcnet_hiddens": [
        4,
        4
      ],
      "fcnet_activation": "tanh",
      "conv_filters": null,
      "conv_activation": "relu",
      "post_fcnet_hiddens": [],
      "post_fcnet_activation": "relu",
      "free_log_std": false,
      "no_final_linear": false,
      "vf_share_layers": false,
      "use_lstm": false,
      "max_seq_len": 20,
      "lstm_cell_size": 256,
      "lstm_use_prev_action": false,
      "lstm_use_prev_reward": false,
      "_time_major": false,
      "use_attention": false,
      "attention_num_transformer_units": 1,
      "attention_dim": 64,
      "attention_num_heads": 1,
      "attention_head_dim": 32,
      "attention_memory_inference": 50,
      "attention_memory_training": 50,
      "attention_position_wise_mlp_dim": 32,
      "attention_init_gru_gate_bias": 2.0,
      "attention_use_n_prev_actions": 0,
      "attention_use_n_prev_rewards": 0,
      "framestack": true,
      "dim": 84,
      "grayscale": false,
      "zero_mean": true,
      "custom_model": null,
      "custom_model_config": {},
      "custom_action_dist": null,
      "custom_preprocessor": null,
      "encoder_latent_dim": null,
      "lstm_use_prev_action_reward": -1,
      "_use_default_native_models": -1
    },
    "optimizer": {},
    "max_requests_in_flight_per_sampler_worker": 2,
    "learner_class": null,
    "_enable_learner_api": false,
    "_learner_hps": "PPOLearnerHPs(kl_coeff=0.2, kl_target=0.01, use_critic=True, clip_param=0.3, vf_clip_param=10.0, entropy_coeff=0.0, vf_loss_coeff=1.0, lr_schedule=None, entropy_coeff_schedule=None)",
    "explore": true,
    "exploration_config": {
      "type": "StochasticSampling"
    },
    "policy_states_are_swappable": false,
    "input_config": {},
    "actions_in_input_normalized": false,
    "postprocess_inputs": false,
    "shuffle_buffer_size": 0,
    "output": null,
    "output_config": {},
    "output_compress_columns": [
      "obs",
      "new_obs"
    ],
    "output_max_file_size": 67108864,
    "offline_sampling": false,
    "evaluation_interval": 1,
    "evaluation_duration": 10,
    "evaluation_duration_unit": "episodes",
    "evaluation_sample_timeout_s": 180.0,
    "evaluation_parallel_to_training": false,
    "evaluation_config": null,
    "off_policy_estimation_methods": {},
    "ope_split_batch_by_episode": true,
    "evaluation_num_workers": 1,
    "always_attach_evaluation_results": false,
    "enable_async_evaluation": false,
    "in_evaluation": false,
    "sync_filters_on_rollout_workers_timeout_s": 60.0,
    "keep_per_episode_custom_metrics": false,
    "metrics_episode_collection_timeout_s": 60.0,
    "metrics_num_episodes_for_smoothing": 100,
    "min_time_s_per_iteration": null,
    "min_train_timesteps_per_iteration": 0,
    "min_sample_timesteps_per_iteration": 0,
    "export_native_model_files": false,
    "checkpoint_trainable_policies_only": false,
    "logger_creator": null,
    "logger_config": null,
    "log_level": "WARN",
    "log_sys_usage": true,
    "fake_sampler": false,
    "seed": null,
    "worker_cls": null,
    "ignore_worker_failures": false,
    "recreate_failed_workers": false,
    "max_num_worker_restarts": 1000,
    "delay_between_worker_restarts_s": 60.0,
    "restart_failed_sub_environments": false,
    "num_consecutive_worker_failures_tolerance": 100,
    "worker_health_probe_timeout_s": 60,
    "worker_restore_timeout_s": 1800,
    "rl_module_spec": null,
    "_enable_rl_module_api": false,
    "_validate_exploration_conf_and_rl_modules": true,
    "_tf_policy_handles_more_than_one_loss": false,
    "_disable_preprocessor_api": false,
    "_disable_action_flattening": false,
    "_disable_execution_plan_api": true,
    "simple_optimizer": true,
    "replay_sequence_length": null,
    "horizon": -1,
    "soft_horizon": -1,
    "no_done_at_end": -1,
    "lr_schedule": null,
    "use_critic": true,
    "use_gae": true,
    "kl_coeff": 0.2,
    "sgd_minibatch_size": 128,
    "num_sgd_iter": 30,
    "shuffle_sequences": true,
    "vf_loss_coeff": 1.0,
    "entropy_coeff": 0.0,
    "entropy_coeff_schedule": null,
    "clip_param": 0.3,
    "vf_clip_param": 10.0,
    "grad_clip": null,
    "kl_target": 0.01,
    "vf_share_layers": -1,
    "__stdout_file__": null,
    "__stderr_file__": null,
    "lambda": 1.0,
    "input": "sampler",
    "multiagent": {
      "policies": {
        "default_policy": [
          null,
          null,
          null,
          null
        ]
      },
      "policy_mapping_fn": "<function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x28f7c7ac0>",
      "policies_to_train": null,
      "policy_map_capacity": 100,
      "policy_map_cache": -1,
      "count_steps_by": "env_steps",
      "observation_fn": null
    },
    "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>",
    "create_env_on_driver": false,
    "custom_eval_function": null,
    "framework": "tf2",
    "num_cpus_for_driver": 1,
    "num_workers": 1
  },
  "time_since_restore": 158.92143607139587,
  "iterations_since_restore": 2,
  "perf": {
    "cpu_util_percent": 42.14144144144144,
    "ram_util_percent": 74.86666666666667
  }
}
{
  "evaluation": {
    "episode_reward_max": 32.0,
    "episode_reward_min": -56.0,
    "episode_reward_mean": -16.4,
    "episode_len_mean": 76.0,
    "episode_media": {},
    "episodes_this_iter": 10,
    "policy_reward_min": {},
    "policy_reward_max": {},
    "policy_reward_mean": {},
    "custom_metrics": {},
    "hist_stats": {
      "episode_reward": [
        -12.0,
        -23.0,
        -23.0,
        -56.0,
        -34.0,
        -1.0,
        32.0,
        -1.0,
        -34.0,
        -12.0
      ],
      "episode_lengths": [
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76
      ]
    },
    "sampler_perf": {
      "mean_raw_obs_processing_ms": 0.1739651840122997,
      "mean_inference_ms": 9.191714478709727,
      "mean_action_processing_ms": 0.07900570840597257,
      "mean_env_wait_ms": 0.039595566732430865,
      "mean_env_render_ms": 0.0
    },
    "num_faulty_episodes": 0,
    "connector_metrics": {
      "ObsPreprocessorConnector_ms": 0.004780292510986328,
      "StateBufferConnector_ms": 0.002562999725341797,
      "ViewRequirementAgentConnector_ms": 0.07958650588989258
    },
    "num_agent_steps_sampled_this_iter": 760,
    "num_env_steps_sampled_this_iter": 760,
    "timesteps_this_iter": 760,
    "num_healthy_workers": 1,
    "num_in_flight_async_reqs": 0,
    "num_remote_worker_restarts": 0
  },
  "custom_metrics": {},
  "episode_media": {},
  "info": {
    "learner": {
      "default_policy": {
        "learner_stats": {
          "cur_kl_coeff": 0.30000001192092896,
          "cur_lr": 0.0010000000474974513,
          "total_loss": 7.9495391845703125,
          "policy_loss": -0.017598839476704597,
          "vf_loss": 7.962441444396973,
          "vf_explained_var": -0.000181463488843292,
          "kl": 0.015653958544135094,
          "entropy": 2.9378433227539062,
          "entropy_coeff": 0.0
        },
        "custom_metrics": {},
        "num_agent_steps_trained": 125.0,
        "num_grad_updates_lifetime": 2400.5,
        "diff_num_grad_updates_vs_sampler_policy": 479.5
      }
    },
    "num_env_steps_sampled": 12000,
    "num_env_steps_trained": 12000,
    "num_agent_steps_sampled": 12000,
    "num_agent_steps_trained": 12000
  },
  "sampler_results": {
    "episode_reward_max": 76.0,
    "episode_reward_min": -122.0,
    "episode_reward_mean": -2.27,
    "episode_len_mean": 76.0,
    "episode_media": {},
    "episodes_this_iter": 52,
    "policy_reward_min": {},
    "policy_reward_max": {},
    "policy_reward_mean": {},
    "custom_metrics": {},
    "hist_stats": {
      "episode_reward": [
        -1.0,
        -1.0,
        -34.0,
        21.0,
        21.0,
        32.0,
        -78.0,
        -1.0,
        21.0,
        -12.0,
        21.0,
        43.0,
        32.0,
        -89.0,
        32.0,
        -34.0,
        -23.0,
        54.0,
        -1.0,
        21.0,
        -12.0,
        -34.0,
        21.0,
        43.0,
        54.0,
        32.0,
        43.0,
        10.0,
        -45.0,
        32.0,
        76.0,
        21.0,
        43.0,
        -23.0,
        32.0,
        10.0,
        -1.0,
        -1.0,
        -1.0,
        10.0,
        21.0,
        -56.0,
        10.0,
        32.0,
        32.0,
        65.0,
        32.0,
        65.0,
        65.0,
        54.0,
        65.0,
        10.0,
        21.0,
        32.0,
        -23.0,
        -45.0,
        -56.0,
        -12.0,
        43.0,
        -12.0,
        -45.0,
        -1.0,
        -45.0,
        -67.0,
        -1.0,
        -111.0,
        -78.0,
        -122.0,
        -34.0,
        10.0,
        -1.0,
        -1.0,
        -34.0,
        10.0,
        -34.0,
        10.0,
        -23.0,
        54.0,
        65.0,
        43.0,
        -40.0,
        -23.0,
        10.0,
        32.0,
        -78.0,
        -45.0,
        -56.0,
        10.0,
        -12.0,
        -23.0,
        54.0,
        -1.0,
        -111.0,
        54.0,
        -45.0,
        -89.0,
        -67.0,
        -45.0,
        -12.0,
        -12.0
      ],
      "episode_lengths": [
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76
      ]
    },
    "sampler_perf": {
      "mean_raw_obs_processing_ms": 0.1848936260485493,
      "mean_inference_ms": 9.25802480544487,
      "mean_action_processing_ms": 0.07683049407794297,
      "mean_env_wait_ms": 0.036541229885124996,
      "mean_env_render_ms": 0.0
    },
    "num_faulty_episodes": 0,
    "connector_metrics": {
      "ObsPreprocessorConnector_ms": 0.004492044448852539,
      "StateBufferConnector_ms": 0.0028548240661621094,
      "ViewRequirementAgentConnector_ms": 0.08351373672485352
    }
  },
  "episode_reward_max": 76.0,
  "episode_reward_min": -122.0,
  "episode_reward_mean": -2.27,
  "episode_len_mean": 76.0,
  "episodes_this_iter": 52,
  "policy_reward_min": {},
  "policy_reward_max": {},
  "policy_reward_mean": {},
  "hist_stats": {
    "episode_reward": [
      -1.0,
      -1.0,
      -34.0,
      21.0,
      21.0,
      32.0,
      -78.0,
      -1.0,
      21.0,
      -12.0,
      21.0,
      43.0,
      32.0,
      -89.0,
      32.0,
      -34.0,
      -23.0,
      54.0,
      -1.0,
      21.0,
      -12.0,
      -34.0,
      21.0,
      43.0,
      54.0,
      32.0,
      43.0,
      10.0,
      -45.0,
      32.0,
      76.0,
      21.0,
      43.0,
      -23.0,
      32.0,
      10.0,
      -1.0,
      -1.0,
      -1.0,
      10.0,
      21.0,
      -56.0,
      10.0,
      32.0,
      32.0,
      65.0,
      32.0,
      65.0,
      65.0,
      54.0,
      65.0,
      10.0,
      21.0,
      32.0,
      -23.0,
      -45.0,
      -56.0,
      -12.0,
      43.0,
      -12.0,
      -45.0,
      -1.0,
      -45.0,
      -67.0,
      -1.0,
      -111.0,
      -78.0,
      -122.0,
      -34.0,
      10.0,
      -1.0,
      -1.0,
      -34.0,
      10.0,
      -34.0,
      10.0,
      -23.0,
      54.0,
      65.0,
      43.0,
      -40.0,
      -23.0,
      10.0,
      32.0,
      -78.0,
      -45.0,
      -56.0,
      10.0,
      -12.0,
      -23.0,
      54.0,
      -1.0,
      -111.0,
      54.0,
      -45.0,
      -89.0,
      -67.0,
      -45.0,
      -12.0,
      -12.0
    ],
    "episode_lengths": [
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76
    ]
  },
  "sampler_perf": {
    "mean_raw_obs_processing_ms": 0.1848936260485493,
    "mean_inference_ms": 9.25802480544487,
    "mean_action_processing_ms": 0.07683049407794297,
    "mean_env_wait_ms": 0.036541229885124996,
    "mean_env_render_ms": 0.0
  },
  "num_faulty_episodes": 0,
  "connector_metrics": {
    "ObsPreprocessorConnector_ms": 0.004492044448852539,
    "StateBufferConnector_ms": 0.0028548240661621094,
    "ViewRequirementAgentConnector_ms": 0.08351373672485352
  },
  "num_healthy_workers": 1,
  "num_in_flight_async_reqs": 0,
  "num_remote_worker_restarts": 0,
  "num_agent_steps_sampled": 12000,
  "num_agent_steps_trained": 12000,
  "num_env_steps_sampled": 12000,
  "num_env_steps_trained": 12000,
  "num_env_steps_sampled_this_iter": 4000,
  "num_env_steps_trained_this_iter": 4000,
  "timesteps_total": 12000,
  "num_steps_trained_this_iter": 4000,
  "agent_timesteps_total": 12000,
  "timers": {
    "training_iteration_time_ms": 71941.107,
    "sample_time_ms": 38225.48,
    "learn_time_ms": 33707.729,
    "learn_throughput": 118.667,
    "synch_weights_time_ms": 6.917
  },
  "counters": {
    "num_env_steps_sampled": 12000,
    "num_env_steps_trained": 12000,
    "num_agent_steps_sampled": 12000,
    "num_agent_steps_trained": 12000
  },
  "done": false,
  "episodes_total": 157,
  "training_iteration": 3,
  "trial_id": "b0a0c_00000",
  "date": "2023-05-31_15-47-19",
  "timestamp": 1685537239,
  "time_this_iter_s": 78.69144916534424,
  "time_total_s": 237.6128852367401,
  "pid": 48728,
  "hostname": "Ozans-MacBook-Pro.local",
  "node_ip": "127.0.0.1",
  "config": {
    "extra_python_environs_for_driver": {},
    "extra_python_environs_for_worker": {},
    "num_gpus": 0,
    "num_cpus_per_worker": 1,
    "num_gpus_per_worker": 0,
    "_fake_gpus": false,
    "num_learner_workers": 0,
    "num_gpus_per_learner_worker": 0,
    "num_cpus_per_learner_worker": 1,
    "local_gpu_idx": 0,
    "custom_resources_per_worker": {},
    "placement_strategy": "PACK",
    "eager_tracing": false,
    "eager_max_retraces": 20,
    "tf_session_args": {
      "intra_op_parallelism_threads": 2,
      "inter_op_parallelism_threads": 2,
      "gpu_options": {
        "allow_growth": true
      },
      "log_device_placement": false,
      "device_count": {
        "CPU": 1
      },
      "allow_soft_placement": true
    },
    "local_tf_session_args": {
      "intra_op_parallelism_threads": 8,
      "inter_op_parallelism_threads": 8
    },
    "env": "Supermarket",
    "env_config": {},
    "observation_space": null,
    "action_space": null,
    "env_task_fn": null,
    "render_env": false,
    "clip_rewards": null,
    "normalize_actions": true,
    "clip_actions": false,
    "disable_env_checking": false,
    "is_atari": false,
    "auto_wrap_old_gym_envs": true,
    "num_envs_per_worker": 1,
    "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>",
    "sample_async": false,
    "enable_connectors": true,
    "rollout_fragment_length": "auto",
    "batch_mode": "truncate_episodes",
    "remote_worker_envs": false,
    "remote_env_batch_wait_ms": 0,
    "validate_workers_after_construction": true,
    "preprocessor_pref": "deepmind",
    "observation_filter": "NoFilter",
    "synchronize_filters": true,
    "compress_observations": false,
    "enable_tf1_exec_eagerly": false,
    "sampler_perf_stats_ema_coef": null,
    "gamma": 0.9,
    "lr": 0.001,
    "train_batch_size": 4000,
    "model": {
      "_disable_preprocessor_api": false,
      "_disable_action_flattening": false,
      "fcnet_hiddens": [
        4,
        4
      ],
      "fcnet_activation": "tanh",
      "conv_filters": null,
      "conv_activation": "relu",
      "post_fcnet_hiddens": [],
      "post_fcnet_activation": "relu",
      "free_log_std": false,
      "no_final_linear": false,
      "vf_share_layers": false,
      "use_lstm": false,
      "max_seq_len": 20,
      "lstm_cell_size": 256,
      "lstm_use_prev_action": false,
      "lstm_use_prev_reward": false,
      "_time_major": false,
      "use_attention": false,
      "attention_num_transformer_units": 1,
      "attention_dim": 64,
      "attention_num_heads": 1,
      "attention_head_dim": 32,
      "attention_memory_inference": 50,
      "attention_memory_training": 50,
      "attention_position_wise_mlp_dim": 32,
      "attention_init_gru_gate_bias": 2.0,
      "attention_use_n_prev_actions": 0,
      "attention_use_n_prev_rewards": 0,
      "framestack": true,
      "dim": 84,
      "grayscale": false,
      "zero_mean": true,
      "custom_model": null,
      "custom_model_config": {},
      "custom_action_dist": null,
      "custom_preprocessor": null,
      "encoder_latent_dim": null,
      "lstm_use_prev_action_reward": -1,
      "_use_default_native_models": -1
    },
    "optimizer": {},
    "max_requests_in_flight_per_sampler_worker": 2,
    "learner_class": null,
    "_enable_learner_api": false,
    "_learner_hps": "PPOLearnerHPs(kl_coeff=0.2, kl_target=0.01, use_critic=True, clip_param=0.3, vf_clip_param=10.0, entropy_coeff=0.0, vf_loss_coeff=1.0, lr_schedule=None, entropy_coeff_schedule=None)",
    "explore": true,
    "exploration_config": {
      "type": "StochasticSampling"
    },
    "policy_states_are_swappable": false,
    "input_config": {},
    "actions_in_input_normalized": false,
    "postprocess_inputs": false,
    "shuffle_buffer_size": 0,
    "output": null,
    "output_config": {},
    "output_compress_columns": [
      "obs",
      "new_obs"
    ],
    "output_max_file_size": 67108864,
    "offline_sampling": false,
    "evaluation_interval": 1,
    "evaluation_duration": 10,
    "evaluation_duration_unit": "episodes",
    "evaluation_sample_timeout_s": 180.0,
    "evaluation_parallel_to_training": false,
    "evaluation_config": null,
    "off_policy_estimation_methods": {},
    "ope_split_batch_by_episode": true,
    "evaluation_num_workers": 1,
    "always_attach_evaluation_results": false,
    "enable_async_evaluation": false,
    "in_evaluation": false,
    "sync_filters_on_rollout_workers_timeout_s": 60.0,
    "keep_per_episode_custom_metrics": false,
    "metrics_episode_collection_timeout_s": 60.0,
    "metrics_num_episodes_for_smoothing": 100,
    "min_time_s_per_iteration": null,
    "min_train_timesteps_per_iteration": 0,
    "min_sample_timesteps_per_iteration": 0,
    "export_native_model_files": false,
    "checkpoint_trainable_policies_only": false,
    "logger_creator": null,
    "logger_config": null,
    "log_level": "WARN",
    "log_sys_usage": true,
    "fake_sampler": false,
    "seed": null,
    "worker_cls": null,
    "ignore_worker_failures": false,
    "recreate_failed_workers": false,
    "max_num_worker_restarts": 1000,
    "delay_between_worker_restarts_s": 60.0,
    "restart_failed_sub_environments": false,
    "num_consecutive_worker_failures_tolerance": 100,
    "worker_health_probe_timeout_s": 60,
    "worker_restore_timeout_s": 1800,
    "rl_module_spec": null,
    "_enable_rl_module_api": false,
    "_validate_exploration_conf_and_rl_modules": true,
    "_tf_policy_handles_more_than_one_loss": false,
    "_disable_preprocessor_api": false,
    "_disable_action_flattening": false,
    "_disable_execution_plan_api": true,
    "simple_optimizer": true,
    "replay_sequence_length": null,
    "horizon": -1,
    "soft_horizon": -1,
    "no_done_at_end": -1,
    "lr_schedule": null,
    "use_critic": true,
    "use_gae": true,
    "kl_coeff": 0.2,
    "sgd_minibatch_size": 128,
    "num_sgd_iter": 30,
    "shuffle_sequences": true,
    "vf_loss_coeff": 1.0,
    "entropy_coeff": 0.0,
    "entropy_coeff_schedule": null,
    "clip_param": 0.3,
    "vf_clip_param": 10.0,
    "grad_clip": null,
    "kl_target": 0.01,
    "vf_share_layers": -1,
    "__stdout_file__": null,
    "__stderr_file__": null,
    "lambda": 1.0,
    "input": "sampler",
    "multiagent": {
      "policies": {
        "default_policy": [
          null,
          null,
          null,
          null
        ]
      },
      "policy_mapping_fn": "<function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x28f7c7ac0>",
      "policies_to_train": null,
      "policy_map_capacity": 100,
      "policy_map_cache": -1,
      "count_steps_by": "env_steps",
      "observation_fn": null
    },
    "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>",
    "create_env_on_driver": false,
    "custom_eval_function": null,
    "framework": "tf2",
    "num_cpus_for_driver": 1,
    "num_workers": 1
  },
  "time_since_restore": 237.6128852367401,
  "iterations_since_restore": 3,
  "perf": {
    "cpu_util_percent": 40.43545454545454,
    "ram_util_percent": 74.65727272727273
  }
}
{
  "evaluation": {
    "episode_reward_max": 43.0,
    "episode_reward_min": -56.0,
    "episode_reward_mean": -9.8,
    "episode_len_mean": 76.0,
    "episode_media": {},
    "episodes_this_iter": 10,
    "policy_reward_min": {},
    "policy_reward_max": {},
    "policy_reward_mean": {},
    "custom_metrics": {},
    "hist_stats": {
      "episode_reward": [
        10.0,
        43.0,
        -56.0,
        -1.0,
        -34.0,
        -12.0,
        -12.0,
        -56.0,
        -1.0,
        21.0
      ],
      "episode_lengths": [
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76
      ]
    },
    "sampler_perf": {
      "mean_raw_obs_processing_ms": 0.17356817677631775,
      "mean_inference_ms": 9.133277304742494,
      "mean_action_processing_ms": 0.0785081569241364,
      "mean_env_wait_ms": 0.0392583905376521,
      "mean_env_render_ms": 0.0
    },
    "num_faulty_episodes": 0,
    "connector_metrics": {
      "ObsPreprocessorConnector_ms": 0.004811286926269531,
      "StateBufferConnector_ms": 0.0026750564575195312,
      "ViewRequirementAgentConnector_ms": 0.08342742919921875
    },
    "num_agent_steps_sampled_this_iter": 760,
    "num_env_steps_sampled_this_iter": 760,
    "timesteps_this_iter": 760,
    "num_healthy_workers": 1,
    "num_in_flight_async_reqs": 0,
    "num_remote_worker_restarts": 0
  },
  "custom_metrics": {},
  "episode_media": {},
  "info": {
    "learner": {
      "default_policy": {
        "learner_stats": {
          "cur_kl_coeff": 0.30000001192092896,
          "cur_lr": 0.0010000000474974513,
          "total_loss": 7.6756591796875,
          "policy_loss": -0.01251723151654005,
          "vf_loss": 7.683739185333252,
          "vf_explained_var": 0.006347115151584148,
          "kl": 0.014789614826440811,
          "entropy": 2.9218509197235107,
          "entropy_coeff": 0.0
        },
        "custom_metrics": {},
        "num_agent_steps_trained": 125.0,
        "num_grad_updates_lifetime": 3360.5,
        "diff_num_grad_updates_vs_sampler_policy": 479.5
      }
    },
    "num_env_steps_sampled": 16000,
    "num_env_steps_trained": 16000,
    "num_agent_steps_sampled": 16000,
    "num_agent_steps_trained": 16000
  },
  "sampler_results": {
    "episode_reward_max": 65.0,
    "episode_reward_min": -122.0,
    "episode_reward_mean": -9.86,
    "episode_len_mean": 76.0,
    "episode_media": {},
    "episodes_this_iter": 53,
    "policy_reward_min": {},
    "policy_reward_max": {},
    "policy_reward_mean": {},
    "custom_metrics": {},
    "hist_stats": {
      "episode_reward": [
        32.0,
        -23.0,
        -45.0,
        -56.0,
        -12.0,
        43.0,
        -12.0,
        -45.0,
        -1.0,
        -45.0,
        -67.0,
        -1.0,
        -111.0,
        -78.0,
        -122.0,
        -34.0,
        10.0,
        -1.0,
        -1.0,
        -34.0,
        10.0,
        -34.0,
        10.0,
        -23.0,
        54.0,
        65.0,
        43.0,
        -40.0,
        -23.0,
        10.0,
        32.0,
        -78.0,
        -45.0,
        -56.0,
        10.0,
        -12.0,
        -23.0,
        54.0,
        -1.0,
        -111.0,
        54.0,
        -45.0,
        -89.0,
        -67.0,
        -45.0,
        -12.0,
        -12.0,
        -23.0,
        -67.0,
        32.0,
        -12.0,
        -45.0,
        -12.0,
        21.0,
        10.0,
        21.0,
        -12.0,
        -1.0,
        10.0,
        -34.0,
        -45.0,
        -1.0,
        -1.0,
        -23.0,
        10.0,
        32.0,
        21.0,
        -12.0,
        -1.0,
        -1.0,
        -12.0,
        21.0,
        21.0,
        43.0,
        54.0,
        43.0,
        21.0,
        -12.0,
        54.0,
        -1.0,
        10.0,
        32.0,
        10.0,
        54.0,
        -34.0,
        -67.0,
        -78.0,
        -34.0,
        10.0,
        -1.0,
        -45.0,
        -12.0,
        54.0,
        21.0,
        10.0,
        43.0,
        -1.0,
        10.0,
        -23.0,
        -67.0
      ],
      "episode_lengths": [
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76
      ]
    },
    "sampler_perf": {
      "mean_raw_obs_processing_ms": 0.18624521571545521,
      "mean_inference_ms": 9.240535044888372,
      "mean_action_processing_ms": 0.07732484679363458,
      "mean_env_wait_ms": 0.03670563255273442,
      "mean_env_render_ms": 0.0
    },
    "num_faulty_episodes": 0,
    "connector_metrics": {
      "ObsPreprocessorConnector_ms": 0.004458904266357422,
      "StateBufferConnector_ms": 0.002866506576538086,
      "ViewRequirementAgentConnector_ms": 0.08307361602783203
    }
  },
  "episode_reward_max": 65.0,
  "episode_reward_min": -122.0,
  "episode_reward_mean": -9.86,
  "episode_len_mean": 76.0,
  "episodes_this_iter": 53,
  "policy_reward_min": {},
  "policy_reward_max": {},
  "policy_reward_mean": {},
  "hist_stats": {
    "episode_reward": [
      32.0,
      -23.0,
      -45.0,
      -56.0,
      -12.0,
      43.0,
      -12.0,
      -45.0,
      -1.0,
      -45.0,
      -67.0,
      -1.0,
      -111.0,
      -78.0,
      -122.0,
      -34.0,
      10.0,
      -1.0,
      -1.0,
      -34.0,
      10.0,
      -34.0,
      10.0,
      -23.0,
      54.0,
      65.0,
      43.0,
      -40.0,
      -23.0,
      10.0,
      32.0,
      -78.0,
      -45.0,
      -56.0,
      10.0,
      -12.0,
      -23.0,
      54.0,
      -1.0,
      -111.0,
      54.0,
      -45.0,
      -89.0,
      -67.0,
      -45.0,
      -12.0,
      -12.0,
      -23.0,
      -67.0,
      32.0,
      -12.0,
      -45.0,
      -12.0,
      21.0,
      10.0,
      21.0,
      -12.0,
      -1.0,
      10.0,
      -34.0,
      -45.0,
      -1.0,
      -1.0,
      -23.0,
      10.0,
      32.0,
      21.0,
      -12.0,
      -1.0,
      -1.0,
      -12.0,
      21.0,
      21.0,
      43.0,
      54.0,
      43.0,
      21.0,
      -12.0,
      54.0,
      -1.0,
      10.0,
      32.0,
      10.0,
      54.0,
      -34.0,
      -67.0,
      -78.0,
      -34.0,
      10.0,
      -1.0,
      -45.0,
      -12.0,
      54.0,
      21.0,
      10.0,
      43.0,
      -1.0,
      10.0,
      -23.0,
      -67.0
    ],
    "episode_lengths": [
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76
    ]
  },
  "sampler_perf": {
    "mean_raw_obs_processing_ms": 0.18624521571545521,
    "mean_inference_ms": 9.240535044888372,
    "mean_action_processing_ms": 0.07732484679363458,
    "mean_env_wait_ms": 0.03670563255273442,
    "mean_env_render_ms": 0.0
  },
  "num_faulty_episodes": 0,
  "connector_metrics": {
    "ObsPreprocessorConnector_ms": 0.004458904266357422,
    "StateBufferConnector_ms": 0.002866506576538086,
    "ViewRequirementAgentConnector_ms": 0.08307361602783203
  },
  "num_healthy_workers": 1,
  "num_in_flight_async_reqs": 0,
  "num_remote_worker_restarts": 0,
  "num_agent_steps_sampled": 16000,
  "num_agent_steps_trained": 16000,
  "num_env_steps_sampled": 16000,
  "num_env_steps_trained": 16000,
  "num_env_steps_sampled_this_iter": 4000,
  "num_env_steps_trained_this_iter": 4000,
  "timesteps_total": 16000,
  "num_steps_trained_this_iter": 4000,
  "agent_timesteps_total": 16000,
  "timers": {
    "training_iteration_time_ms": 71672.996,
    "sample_time_ms": 38185.178,
    "learn_time_ms": 33480.068,
    "learn_throughput": 119.474,
    "synch_weights_time_ms": 6.888
  },
  "counters": {
    "num_env_steps_sampled": 16000,
    "num_env_steps_trained": 16000,
    "num_agent_steps_sampled": 16000,
    "num_agent_steps_trained": 16000
  },
  "done": false,
  "episodes_total": 210,
  "training_iteration": 4,
  "trial_id": "b0a0c_00000",
  "date": "2023-05-31_15-48-37",
  "timestamp": 1685537317,
  "time_this_iter_s": 77.93973302841187,
  "time_total_s": 315.552618265152,
  "pid": 48728,
  "hostname": "Ozans-MacBook-Pro.local",
  "node_ip": "127.0.0.1",
  "config": {
    "extra_python_environs_for_driver": {},
    "extra_python_environs_for_worker": {},
    "num_gpus": 0,
    "num_cpus_per_worker": 1,
    "num_gpus_per_worker": 0,
    "_fake_gpus": false,
    "num_learner_workers": 0,
    "num_gpus_per_learner_worker": 0,
    "num_cpus_per_learner_worker": 1,
    "local_gpu_idx": 0,
    "custom_resources_per_worker": {},
    "placement_strategy": "PACK",
    "eager_tracing": false,
    "eager_max_retraces": 20,
    "tf_session_args": {
      "intra_op_parallelism_threads": 2,
      "inter_op_parallelism_threads": 2,
      "gpu_options": {
        "allow_growth": true
      },
      "log_device_placement": false,
      "device_count": {
        "CPU": 1
      },
      "allow_soft_placement": true
    },
    "local_tf_session_args": {
      "intra_op_parallelism_threads": 8,
      "inter_op_parallelism_threads": 8
    },
    "env": "Supermarket",
    "env_config": {},
    "observation_space": null,
    "action_space": null,
    "env_task_fn": null,
    "render_env": false,
    "clip_rewards": null,
    "normalize_actions": true,
    "clip_actions": false,
    "disable_env_checking": false,
    "is_atari": false,
    "auto_wrap_old_gym_envs": true,
    "num_envs_per_worker": 1,
    "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>",
    "sample_async": false,
    "enable_connectors": true,
    "rollout_fragment_length": "auto",
    "batch_mode": "truncate_episodes",
    "remote_worker_envs": false,
    "remote_env_batch_wait_ms": 0,
    "validate_workers_after_construction": true,
    "preprocessor_pref": "deepmind",
    "observation_filter": "NoFilter",
    "synchronize_filters": true,
    "compress_observations": false,
    "enable_tf1_exec_eagerly": false,
    "sampler_perf_stats_ema_coef": null,
    "gamma": 0.9,
    "lr": 0.001,
    "train_batch_size": 4000,
    "model": {
      "_disable_preprocessor_api": false,
      "_disable_action_flattening": false,
      "fcnet_hiddens": [
        4,
        4
      ],
      "fcnet_activation": "tanh",
      "conv_filters": null,
      "conv_activation": "relu",
      "post_fcnet_hiddens": [],
      "post_fcnet_activation": "relu",
      "free_log_std": false,
      "no_final_linear": false,
      "vf_share_layers": false,
      "use_lstm": false,
      "max_seq_len": 20,
      "lstm_cell_size": 256,
      "lstm_use_prev_action": false,
      "lstm_use_prev_reward": false,
      "_time_major": false,
      "use_attention": false,
      "attention_num_transformer_units": 1,
      "attention_dim": 64,
      "attention_num_heads": 1,
      "attention_head_dim": 32,
      "attention_memory_inference": 50,
      "attention_memory_training": 50,
      "attention_position_wise_mlp_dim": 32,
      "attention_init_gru_gate_bias": 2.0,
      "attention_use_n_prev_actions": 0,
      "attention_use_n_prev_rewards": 0,
      "framestack": true,
      "dim": 84,
      "grayscale": false,
      "zero_mean": true,
      "custom_model": null,
      "custom_model_config": {},
      "custom_action_dist": null,
      "custom_preprocessor": null,
      "encoder_latent_dim": null,
      "lstm_use_prev_action_reward": -1,
      "_use_default_native_models": -1
    },
    "optimizer": {},
    "max_requests_in_flight_per_sampler_worker": 2,
    "learner_class": null,
    "_enable_learner_api": false,
    "_learner_hps": "PPOLearnerHPs(kl_coeff=0.2, kl_target=0.01, use_critic=True, clip_param=0.3, vf_clip_param=10.0, entropy_coeff=0.0, vf_loss_coeff=1.0, lr_schedule=None, entropy_coeff_schedule=None)",
    "explore": true,
    "exploration_config": {
      "type": "StochasticSampling"
    },
    "policy_states_are_swappable": false,
    "input_config": {},
    "actions_in_input_normalized": false,
    "postprocess_inputs": false,
    "shuffle_buffer_size": 0,
    "output": null,
    "output_config": {},
    "output_compress_columns": [
      "obs",
      "new_obs"
    ],
    "output_max_file_size": 67108864,
    "offline_sampling": false,
    "evaluation_interval": 1,
    "evaluation_duration": 10,
    "evaluation_duration_unit": "episodes",
    "evaluation_sample_timeout_s": 180.0,
    "evaluation_parallel_to_training": false,
    "evaluation_config": null,
    "off_policy_estimation_methods": {},
    "ope_split_batch_by_episode": true,
    "evaluation_num_workers": 1,
    "always_attach_evaluation_results": false,
    "enable_async_evaluation": false,
    "in_evaluation": false,
    "sync_filters_on_rollout_workers_timeout_s": 60.0,
    "keep_per_episode_custom_metrics": false,
    "metrics_episode_collection_timeout_s": 60.0,
    "metrics_num_episodes_for_smoothing": 100,
    "min_time_s_per_iteration": null,
    "min_train_timesteps_per_iteration": 0,
    "min_sample_timesteps_per_iteration": 0,
    "export_native_model_files": false,
    "checkpoint_trainable_policies_only": false,
    "logger_creator": null,
    "logger_config": null,
    "log_level": "WARN",
    "log_sys_usage": true,
    "fake_sampler": false,
    "seed": null,
    "worker_cls": null,
    "ignore_worker_failures": false,
    "recreate_failed_workers": false,
    "max_num_worker_restarts": 1000,
    "delay_between_worker_restarts_s": 60.0,
    "restart_failed_sub_environments": false,
    "num_consecutive_worker_failures_tolerance": 100,
    "worker_health_probe_timeout_s": 60,
    "worker_restore_timeout_s": 1800,
    "rl_module_spec": null,
    "_enable_rl_module_api": false,
    "_validate_exploration_conf_and_rl_modules": true,
    "_tf_policy_handles_more_than_one_loss": false,
    "_disable_preprocessor_api": false,
    "_disable_action_flattening": false,
    "_disable_execution_plan_api": true,
    "simple_optimizer": true,
    "replay_sequence_length": null,
    "horizon": -1,
    "soft_horizon": -1,
    "no_done_at_end": -1,
    "lr_schedule": null,
    "use_critic": true,
    "use_gae": true,
    "kl_coeff": 0.2,
    "sgd_minibatch_size": 128,
    "num_sgd_iter": 30,
    "shuffle_sequences": true,
    "vf_loss_coeff": 1.0,
    "entropy_coeff": 0.0,
    "entropy_coeff_schedule": null,
    "clip_param": 0.3,
    "vf_clip_param": 10.0,
    "grad_clip": null,
    "kl_target": 0.01,
    "vf_share_layers": -1,
    "__stdout_file__": null,
    "__stderr_file__": null,
    "lambda": 1.0,
    "input": "sampler",
    "multiagent": {
      "policies": {
        "default_policy": [
          null,
          null,
          null,
          null
        ]
      },
      "policy_mapping_fn": "<function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x28f7c7ac0>",
      "policies_to_train": null,
      "policy_map_capacity": 100,
      "policy_map_cache": -1,
      "count_steps_by": "env_steps",
      "observation_fn": null
    },
    "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>",
    "create_env_on_driver": false,
    "custom_eval_function": null,
    "framework": "tf2",
    "num_cpus_for_driver": 1,
    "num_workers": 1
  },
  "time_since_restore": 315.552618265152,
  "iterations_since_restore": 4,
  "perf": {
    "cpu_util_percent": 39.9091743119266,
    "ram_util_percent": 74.82018348623853
  }
}
{
  "evaluation": {
    "episode_reward_max": 21.0,
    "episode_reward_min": -100.0,
    "episode_reward_mean": -14.8,
    "episode_len_mean": 76.0,
    "episode_media": {},
    "episodes_this_iter": 10,
    "policy_reward_min": {},
    "policy_reward_max": {},
    "policy_reward_mean": {},
    "custom_metrics": {},
    "hist_stats": {
      "episode_reward": [
        21.0,
        21.0,
        21.0,
        -100.0,
        10.0,
        -23.0,
        -73.0,
        -12.0,
        -1.0,
        -12.0
      ],
      "episode_lengths": [
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76
      ]
    },
    "sampler_perf": {
      "mean_raw_obs_processing_ms": 0.1734391979969228,
      "mean_inference_ms": 9.110625936181506,
      "mean_action_processing_ms": 0.07809817367589841,
      "mean_env_wait_ms": 0.039013082558968855,
      "mean_env_render_ms": 0.0
    },
    "num_faulty_episodes": 0,
    "connector_metrics": {
      "ObsPreprocessorConnector_ms": 0.004363059997558594,
      "StateBufferConnector_ms": 0.0026416778564453125,
      "ViewRequirementAgentConnector_ms": 0.08249759674072266
    },
    "num_agent_steps_sampled_this_iter": 760,
    "num_env_steps_sampled_this_iter": 760,
    "timesteps_this_iter": 760,
    "num_healthy_workers": 1,
    "num_in_flight_async_reqs": 0,
    "num_remote_worker_restarts": 0
  },
  "custom_metrics": {},
  "episode_media": {},
  "info": {
    "learner": {
      "default_policy": {
        "learner_stats": {
          "cur_kl_coeff": 0.30000001192092896,
          "cur_lr": 0.0010000000474974513,
          "total_loss": 7.625319480895996,
          "policy_loss": -0.016662394627928734,
          "vf_loss": 7.636350154876709,
          "vf_explained_var": -0.006585045717656612,
          "kl": 0.018773026764392853,
          "entropy": 2.902233839035034,
          "entropy_coeff": 0.0
        },
        "custom_metrics": {},
        "num_agent_steps_trained": 125.0,
        "num_grad_updates_lifetime": 4320.5,
        "diff_num_grad_updates_vs_sampler_policy": 479.5
      }
    },
    "num_env_steps_sampled": 20000,
    "num_env_steps_trained": 20000,
    "num_agent_steps_sampled": 20000,
    "num_agent_steps_trained": 20000
  },
  "sampler_results": {
    "episode_reward_max": 76.0,
    "episode_reward_min": -89.0,
    "episode_reward_mean": 6.59,
    "episode_len_mean": 76.0,
    "episode_media": {},
    "episodes_this_iter": 53,
    "policy_reward_min": {},
    "policy_reward_max": {},
    "policy_reward_mean": {},
    "custom_metrics": {},
    "hist_stats": {
      "episode_reward": [
        21.0,
        10.0,
        21.0,
        -12.0,
        -1.0,
        10.0,
        -34.0,
        -45.0,
        -1.0,
        -1.0,
        -23.0,
        10.0,
        32.0,
        21.0,
        -12.0,
        -1.0,
        -1.0,
        -12.0,
        21.0,
        21.0,
        43.0,
        54.0,
        43.0,
        21.0,
        -12.0,
        54.0,
        -1.0,
        10.0,
        32.0,
        10.0,
        54.0,
        -34.0,
        -67.0,
        -78.0,
        -34.0,
        10.0,
        -1.0,
        -45.0,
        -12.0,
        54.0,
        21.0,
        10.0,
        43.0,
        -1.0,
        10.0,
        -23.0,
        -67.0,
        -12.0,
        -45.0,
        21.0,
        65.0,
        65.0,
        43.0,
        -1.0,
        54.0,
        32.0,
        -1.0,
        43.0,
        65.0,
        43.0,
        -1.0,
        -34.0,
        21.0,
        -1.0,
        -1.0,
        10.0,
        32.0,
        -23.0,
        54.0,
        -23.0,
        10.0,
        -12.0,
        -56.0,
        65.0,
        43.0,
        -12.0,
        21.0,
        43.0,
        76.0,
        54.0,
        -34.0,
        43.0,
        -67.0,
        10.0,
        -34.0,
        10.0,
        43.0,
        10.0,
        43.0,
        54.0,
        -1.0,
        -23.0,
        -23.0,
        -56.0,
        21.0,
        -1.0,
        -23.0,
        21.0,
        -1.0,
        -89.0
      ],
      "episode_lengths": [
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76
      ]
    },
    "sampler_perf": {
      "mean_raw_obs_processing_ms": 0.1869822949973697,
      "mean_inference_ms": 9.232876137394781,
      "mean_action_processing_ms": 0.077580509193251,
      "mean_env_wait_ms": 0.03679143197075684,
      "mean_env_render_ms": 0.0
    },
    "num_faulty_episodes": 0,
    "connector_metrics": {
      "ObsPreprocessorConnector_ms": 0.004382133483886719,
      "StateBufferConnector_ms": 0.0028166770935058594,
      "ViewRequirementAgentConnector_ms": 0.08345580101013184
    }
  },
  "episode_reward_max": 76.0,
  "episode_reward_min": -89.0,
  "episode_reward_mean": 6.59,
  "episode_len_mean": 76.0,
  "episodes_this_iter": 53,
  "policy_reward_min": {},
  "policy_reward_max": {},
  "policy_reward_mean": {},
  "hist_stats": {
    "episode_reward": [
      21.0,
      10.0,
      21.0,
      -12.0,
      -1.0,
      10.0,
      -34.0,
      -45.0,
      -1.0,
      -1.0,
      -23.0,
      10.0,
      32.0,
      21.0,
      -12.0,
      -1.0,
      -1.0,
      -12.0,
      21.0,
      21.0,
      43.0,
      54.0,
      43.0,
      21.0,
      -12.0,
      54.0,
      -1.0,
      10.0,
      32.0,
      10.0,
      54.0,
      -34.0,
      -67.0,
      -78.0,
      -34.0,
      10.0,
      -1.0,
      -45.0,
      -12.0,
      54.0,
      21.0,
      10.0,
      43.0,
      -1.0,
      10.0,
      -23.0,
      -67.0,
      -12.0,
      -45.0,
      21.0,
      65.0,
      65.0,
      43.0,
      -1.0,
      54.0,
      32.0,
      -1.0,
      43.0,
      65.0,
      43.0,
      -1.0,
      -34.0,
      21.0,
      -1.0,
      -1.0,
      10.0,
      32.0,
      -23.0,
      54.0,
      -23.0,
      10.0,
      -12.0,
      -56.0,
      65.0,
      43.0,
      -12.0,
      21.0,
      43.0,
      76.0,
      54.0,
      -34.0,
      43.0,
      -67.0,
      10.0,
      -34.0,
      10.0,
      43.0,
      10.0,
      43.0,
      54.0,
      -1.0,
      -23.0,
      -23.0,
      -56.0,
      21.0,
      -1.0,
      -23.0,
      21.0,
      -1.0,
      -89.0
    ],
    "episode_lengths": [
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76
    ]
  },
  "sampler_perf": {
    "mean_raw_obs_processing_ms": 0.1869822949973697,
    "mean_inference_ms": 9.232876137394781,
    "mean_action_processing_ms": 0.077580509193251,
    "mean_env_wait_ms": 0.03679143197075684,
    "mean_env_render_ms": 0.0
  },
  "num_faulty_episodes": 0,
  "connector_metrics": {
    "ObsPreprocessorConnector_ms": 0.004382133483886719,
    "StateBufferConnector_ms": 0.0028166770935058594,
    "ViewRequirementAgentConnector_ms": 0.08345580101013184
  },
  "num_healthy_workers": 1,
  "num_in_flight_async_reqs": 0,
  "num_remote_worker_restarts": 0,
  "num_agent_steps_sampled": 20000,
  "num_agent_steps_trained": 20000,
  "num_env_steps_sampled": 20000,
  "num_env_steps_trained": 20000,
  "num_env_steps_sampled_this_iter": 4000,
  "num_env_steps_trained_this_iter": 4000,
  "timesteps_total": 20000,
  "num_steps_trained_this_iter": 4000,
  "agent_timesteps_total": 20000,
  "timers": {
    "training_iteration_time_ms": 71541.257,
    "sample_time_ms": 38170.125,
    "learn_time_ms": 33363.399,
    "learn_throughput": 119.892,
    "synch_weights_time_ms": 6.944
  },
  "counters": {
    "num_env_steps_sampled": 20000,
    "num_env_steps_trained": 20000,
    "num_agent_steps_sampled": 20000,
    "num_agent_steps_trained": 20000
  },
  "done": false,
  "episodes_total": 263,
  "training_iteration": 5,
  "trial_id": "b0a0c_00000",
  "date": "2023-05-31_15-49-55",
  "timestamp": 1685537395,
  "time_this_iter_s": 78.13539695739746,
  "time_total_s": 393.68801522254944,
  "pid": 48728,
  "hostname": "Ozans-MacBook-Pro.local",
  "node_ip": "127.0.0.1",
  "config": {
    "extra_python_environs_for_driver": {},
    "extra_python_environs_for_worker": {},
    "num_gpus": 0,
    "num_cpus_per_worker": 1,
    "num_gpus_per_worker": 0,
    "_fake_gpus": false,
    "num_learner_workers": 0,
    "num_gpus_per_learner_worker": 0,
    "num_cpus_per_learner_worker": 1,
    "local_gpu_idx": 0,
    "custom_resources_per_worker": {},
    "placement_strategy": "PACK",
    "eager_tracing": false,
    "eager_max_retraces": 20,
    "tf_session_args": {
      "intra_op_parallelism_threads": 2,
      "inter_op_parallelism_threads": 2,
      "gpu_options": {
        "allow_growth": true
      },
      "log_device_placement": false,
      "device_count": {
        "CPU": 1
      },
      "allow_soft_placement": true
    },
    "local_tf_session_args": {
      "intra_op_parallelism_threads": 8,
      "inter_op_parallelism_threads": 8
    },
    "env": "Supermarket",
    "env_config": {},
    "observation_space": null,
    "action_space": null,
    "env_task_fn": null,
    "render_env": false,
    "clip_rewards": null,
    "normalize_actions": true,
    "clip_actions": false,
    "disable_env_checking": false,
    "is_atari": false,
    "auto_wrap_old_gym_envs": true,
    "num_envs_per_worker": 1,
    "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>",
    "sample_async": false,
    "enable_connectors": true,
    "rollout_fragment_length": "auto",
    "batch_mode": "truncate_episodes",
    "remote_worker_envs": false,
    "remote_env_batch_wait_ms": 0,
    "validate_workers_after_construction": true,
    "preprocessor_pref": "deepmind",
    "observation_filter": "NoFilter",
    "synchronize_filters": true,
    "compress_observations": false,
    "enable_tf1_exec_eagerly": false,
    "sampler_perf_stats_ema_coef": null,
    "gamma": 0.9,
    "lr": 0.001,
    "train_batch_size": 4000,
    "model": {
      "_disable_preprocessor_api": false,
      "_disable_action_flattening": false,
      "fcnet_hiddens": [
        4,
        4
      ],
      "fcnet_activation": "tanh",
      "conv_filters": null,
      "conv_activation": "relu",
      "post_fcnet_hiddens": [],
      "post_fcnet_activation": "relu",
      "free_log_std": false,
      "no_final_linear": false,
      "vf_share_layers": false,
      "use_lstm": false,
      "max_seq_len": 20,
      "lstm_cell_size": 256,
      "lstm_use_prev_action": false,
      "lstm_use_prev_reward": false,
      "_time_major": false,
      "use_attention": false,
      "attention_num_transformer_units": 1,
      "attention_dim": 64,
      "attention_num_heads": 1,
      "attention_head_dim": 32,
      "attention_memory_inference": 50,
      "attention_memory_training": 50,
      "attention_position_wise_mlp_dim": 32,
      "attention_init_gru_gate_bias": 2.0,
      "attention_use_n_prev_actions": 0,
      "attention_use_n_prev_rewards": 0,
      "framestack": true,
      "dim": 84,
      "grayscale": false,
      "zero_mean": true,
      "custom_model": null,
      "custom_model_config": {},
      "custom_action_dist": null,
      "custom_preprocessor": null,
      "encoder_latent_dim": null,
      "lstm_use_prev_action_reward": -1,
      "_use_default_native_models": -1
    },
    "optimizer": {},
    "max_requests_in_flight_per_sampler_worker": 2,
    "learner_class": null,
    "_enable_learner_api": false,
    "_learner_hps": "PPOLearnerHPs(kl_coeff=0.2, kl_target=0.01, use_critic=True, clip_param=0.3, vf_clip_param=10.0, entropy_coeff=0.0, vf_loss_coeff=1.0, lr_schedule=None, entropy_coeff_schedule=None)",
    "explore": true,
    "exploration_config": {
      "type": "StochasticSampling"
    },
    "policy_states_are_swappable": false,
    "input_config": {},
    "actions_in_input_normalized": false,
    "postprocess_inputs": false,
    "shuffle_buffer_size": 0,
    "output": null,
    "output_config": {},
    "output_compress_columns": [
      "obs",
      "new_obs"
    ],
    "output_max_file_size": 67108864,
    "offline_sampling": false,
    "evaluation_interval": 1,
    "evaluation_duration": 10,
    "evaluation_duration_unit": "episodes",
    "evaluation_sample_timeout_s": 180.0,
    "evaluation_parallel_to_training": false,
    "evaluation_config": null,
    "off_policy_estimation_methods": {},
    "ope_split_batch_by_episode": true,
    "evaluation_num_workers": 1,
    "always_attach_evaluation_results": false,
    "enable_async_evaluation": false,
    "in_evaluation": false,
    "sync_filters_on_rollout_workers_timeout_s": 60.0,
    "keep_per_episode_custom_metrics": false,
    "metrics_episode_collection_timeout_s": 60.0,
    "metrics_num_episodes_for_smoothing": 100,
    "min_time_s_per_iteration": null,
    "min_train_timesteps_per_iteration": 0,
    "min_sample_timesteps_per_iteration": 0,
    "export_native_model_files": false,
    "checkpoint_trainable_policies_only": false,
    "logger_creator": null,
    "logger_config": null,
    "log_level": "WARN",
    "log_sys_usage": true,
    "fake_sampler": false,
    "seed": null,
    "worker_cls": null,
    "ignore_worker_failures": false,
    "recreate_failed_workers": false,
    "max_num_worker_restarts": 1000,
    "delay_between_worker_restarts_s": 60.0,
    "restart_failed_sub_environments": false,
    "num_consecutive_worker_failures_tolerance": 100,
    "worker_health_probe_timeout_s": 60,
    "worker_restore_timeout_s": 1800,
    "rl_module_spec": null,
    "_enable_rl_module_api": false,
    "_validate_exploration_conf_and_rl_modules": true,
    "_tf_policy_handles_more_than_one_loss": false,
    "_disable_preprocessor_api": false,
    "_disable_action_flattening": false,
    "_disable_execution_plan_api": true,
    "simple_optimizer": true,
    "replay_sequence_length": null,
    "horizon": -1,
    "soft_horizon": -1,
    "no_done_at_end": -1,
    "lr_schedule": null,
    "use_critic": true,
    "use_gae": true,
    "kl_coeff": 0.2,
    "sgd_minibatch_size": 128,
    "num_sgd_iter": 30,
    "shuffle_sequences": true,
    "vf_loss_coeff": 1.0,
    "entropy_coeff": 0.0,
    "entropy_coeff_schedule": null,
    "clip_param": 0.3,
    "vf_clip_param": 10.0,
    "grad_clip": null,
    "kl_target": 0.01,
    "vf_share_layers": -1,
    "__stdout_file__": null,
    "__stderr_file__": null,
    "lambda": 1.0,
    "input": "sampler",
    "multiagent": {
      "policies": {
        "default_policy": [
          null,
          null,
          null,
          null
        ]
      },
      "policy_mapping_fn": "<function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x28f7c7ac0>",
      "policies_to_train": null,
      "policy_map_capacity": 100,
      "policy_map_cache": -1,
      "count_steps_by": "env_steps",
      "observation_fn": null
    },
    "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>",
    "create_env_on_driver": false,
    "custom_eval_function": null,
    "framework": "tf2",
    "num_cpus_for_driver": 1,
    "num_workers": 1
  },
  "time_since_restore": 393.68801522254944,
  "iterations_since_restore": 5,
  "perf": {
    "cpu_util_percent": 46.193577981651366,
    "ram_util_percent": 74.5137614678899
  }
}
{
  "evaluation": {
    "episode_reward_max": 76.0,
    "episode_reward_min": -56.0,
    "episode_reward_mean": 16.0,
    "episode_len_mean": 76.0,
    "episode_media": {},
    "episodes_this_iter": 10,
    "policy_reward_min": {},
    "policy_reward_max": {},
    "policy_reward_mean": {},
    "custom_metrics": {},
    "hist_stats": {
      "episode_reward": [
        43.0,
        54.0,
        10.0,
        -12.0,
        76.0,
        21.0,
        -34.0,
        -56.0,
        43.0,
        15.0
      ],
      "episode_lengths": [
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76
      ]
    },
    "sampler_perf": {
      "mean_raw_obs_processing_ms": 0.17448371765096574,
      "mean_inference_ms": 9.275007080650202,
      "mean_action_processing_ms": 0.0786795424829578,
      "mean_env_wait_ms": 0.03943655527989297,
      "mean_env_render_ms": 0.0
    },
    "num_faulty_episodes": 0,
    "connector_metrics": {
      "ObsPreprocessorConnector_ms": 0.005240440368652344,
      "StateBufferConnector_ms": 0.002715587615966797,
      "ViewRequirementAgentConnector_ms": 0.08923530578613281
    },
    "num_agent_steps_sampled_this_iter": 760,
    "num_env_steps_sampled_this_iter": 760,
    "timesteps_this_iter": 760,
    "num_healthy_workers": 1,
    "num_in_flight_async_reqs": 0,
    "num_remote_worker_restarts": 0
  },
  "custom_metrics": {},
  "episode_media": {},
  "info": {
    "learner": {
      "default_policy": {
        "learner_stats": {
          "cur_kl_coeff": 0.30000001192092896,
          "cur_lr": 0.0010000000474974513,
          "total_loss": 7.503093242645264,
          "policy_loss": -0.02063949592411518,
          "vf_loss": 7.517218112945557,
          "vf_explained_var": 0.001124200178310275,
          "kl": 0.021716849878430367,
          "entropy": 2.876429796218872,
          "entropy_coeff": 0.0
        },
        "custom_metrics": {},
        "num_agent_steps_trained": 125.0,
        "num_grad_updates_lifetime": 5280.5,
        "diff_num_grad_updates_vs_sampler_policy": 479.5
      }
    },
    "num_env_steps_sampled": 24000,
    "num_env_steps_trained": 24000,
    "num_agent_steps_sampled": 24000,
    "num_agent_steps_trained": 24000
  },
  "sampler_results": {
    "episode_reward_max": 76.0,
    "episode_reward_min": -89.0,
    "episode_reward_mean": 9.45,
    "episode_len_mean": 76.0,
    "episode_media": {},
    "episodes_this_iter": 52,
    "policy_reward_min": {},
    "policy_reward_max": {},
    "policy_reward_mean": {},
    "custom_metrics": {},
    "hist_stats": {
      "episode_reward": [
        43.0,
        -1.0,
        54.0,
        32.0,
        -1.0,
        43.0,
        65.0,
        43.0,
        -1.0,
        -34.0,
        21.0,
        -1.0,
        -1.0,
        10.0,
        32.0,
        -23.0,
        54.0,
        -23.0,
        10.0,
        -12.0,
        -56.0,
        65.0,
        43.0,
        -12.0,
        21.0,
        43.0,
        76.0,
        54.0,
        -34.0,
        43.0,
        -67.0,
        10.0,
        -34.0,
        10.0,
        43.0,
        10.0,
        43.0,
        54.0,
        -1.0,
        -23.0,
        -23.0,
        -56.0,
        21.0,
        -1.0,
        -23.0,
        21.0,
        -1.0,
        -89.0,
        43.0,
        43.0,
        -1.0,
        -1.0,
        -45.0,
        21.0,
        54.0,
        21.0,
        54.0,
        10.0,
        54.0,
        10.0,
        -12.0,
        -23.0,
        -23.0,
        -1.0,
        -12.0,
        -23.0,
        -45.0,
        -23.0,
        -34.0,
        21.0,
        32.0,
        54.0,
        54.0,
        -23.0,
        32.0,
        -12.0,
        -34.0,
        65.0,
        -12.0,
        -34.0,
        32.0,
        -45.0,
        21.0,
        -23.0,
        -34.0,
        10.0,
        10.0,
        10.0,
        32.0,
        -1.0,
        43.0,
        21.0,
        65.0,
        32.0,
        -12.0,
        10.0,
        10.0,
        32.0,
        21.0,
        54.0
      ],
      "episode_lengths": [
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76
      ]
    },
    "sampler_perf": {
      "mean_raw_obs_processing_ms": 0.18742127887048002,
      "mean_inference_ms": 9.232399746427557,
      "mean_action_processing_ms": 0.07775008177233607,
      "mean_env_wait_ms": 0.03683176102501265,
      "mean_env_render_ms": 0.0
    },
    "num_faulty_episodes": 0,
    "connector_metrics": {
      "ObsPreprocessorConnector_ms": 0.0044939517974853516,
      "StateBufferConnector_ms": 0.0028181076049804688,
      "ViewRequirementAgentConnector_ms": 0.08486390113830566
    }
  },
  "episode_reward_max": 76.0,
  "episode_reward_min": -89.0,
  "episode_reward_mean": 9.45,
  "episode_len_mean": 76.0,
  "episodes_this_iter": 52,
  "policy_reward_min": {},
  "policy_reward_max": {},
  "policy_reward_mean": {},
  "hist_stats": {
    "episode_reward": [
      43.0,
      -1.0,
      54.0,
      32.0,
      -1.0,
      43.0,
      65.0,
      43.0,
      -1.0,
      -34.0,
      21.0,
      -1.0,
      -1.0,
      10.0,
      32.0,
      -23.0,
      54.0,
      -23.0,
      10.0,
      -12.0,
      -56.0,
      65.0,
      43.0,
      -12.0,
      21.0,
      43.0,
      76.0,
      54.0,
      -34.0,
      43.0,
      -67.0,
      10.0,
      -34.0,
      10.0,
      43.0,
      10.0,
      43.0,
      54.0,
      -1.0,
      -23.0,
      -23.0,
      -56.0,
      21.0,
      -1.0,
      -23.0,
      21.0,
      -1.0,
      -89.0,
      43.0,
      43.0,
      -1.0,
      -1.0,
      -45.0,
      21.0,
      54.0,
      21.0,
      54.0,
      10.0,
      54.0,
      10.0,
      -12.0,
      -23.0,
      -23.0,
      -1.0,
      -12.0,
      -23.0,
      -45.0,
      -23.0,
      -34.0,
      21.0,
      32.0,
      54.0,
      54.0,
      -23.0,
      32.0,
      -12.0,
      -34.0,
      65.0,
      -12.0,
      -34.0,
      32.0,
      -45.0,
      21.0,
      -23.0,
      -34.0,
      10.0,
      10.0,
      10.0,
      32.0,
      -1.0,
      43.0,
      21.0,
      65.0,
      32.0,
      -12.0,
      10.0,
      10.0,
      32.0,
      21.0,
      54.0
    ],
    "episode_lengths": [
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76
    ]
  },
  "sampler_perf": {
    "mean_raw_obs_processing_ms": 0.18742127887048002,
    "mean_inference_ms": 9.232399746427557,
    "mean_action_processing_ms": 0.07775008177233607,
    "mean_env_wait_ms": 0.03683176102501265,
    "mean_env_render_ms": 0.0
  },
  "num_faulty_episodes": 0,
  "connector_metrics": {
    "ObsPreprocessorConnector_ms": 0.0044939517974853516,
    "StateBufferConnector_ms": 0.0028181076049804688,
    "ViewRequirementAgentConnector_ms": 0.08486390113830566
  },
  "num_healthy_workers": 1,
  "num_in_flight_async_reqs": 0,
  "num_remote_worker_restarts": 0,
  "num_agent_steps_sampled": 24000,
  "num_agent_steps_trained": 24000,
  "num_env_steps_sampled": 24000,
  "num_env_steps_trained": 24000,
  "num_env_steps_sampled_this_iter": 4000,
  "num_env_steps_trained_this_iter": 4000,
  "timesteps_total": 24000,
  "num_steps_trained_this_iter": 4000,
  "agent_timesteps_total": 24000,
  "timers": {
    "training_iteration_time_ms": 71744.428,
    "sample_time_ms": 38184.3,
    "learn_time_ms": 33552.268,
    "learn_throughput": 119.217,
    "synch_weights_time_ms": 7.047
  },
  "counters": {
    "num_env_steps_sampled": 24000,
    "num_env_steps_trained": 24000,
    "num_agent_steps_sampled": 24000,
    "num_agent_steps_trained": 24000
  },
  "done": false,
  "episodes_total": 315,
  "training_iteration": 6,
  "trial_id": "b0a0c_00000",
  "date": "2023-05-31_15-51-16",
  "timestamp": 1685537476,
  "time_this_iter_s": 80.71445989608765,
  "time_total_s": 474.4024751186371,
  "pid": 48728,
  "hostname": "Ozans-MacBook-Pro.local",
  "node_ip": "127.0.0.1",
  "config": {
    "extra_python_environs_for_driver": {},
    "extra_python_environs_for_worker": {},
    "num_gpus": 0,
    "num_cpus_per_worker": 1,
    "num_gpus_per_worker": 0,
    "_fake_gpus": false,
    "num_learner_workers": 0,
    "num_gpus_per_learner_worker": 0,
    "num_cpus_per_learner_worker": 1,
    "local_gpu_idx": 0,
    "custom_resources_per_worker": {},
    "placement_strategy": "PACK",
    "eager_tracing": false,
    "eager_max_retraces": 20,
    "tf_session_args": {
      "intra_op_parallelism_threads": 2,
      "inter_op_parallelism_threads": 2,
      "gpu_options": {
        "allow_growth": true
      },
      "log_device_placement": false,
      "device_count": {
        "CPU": 1
      },
      "allow_soft_placement": true
    },
    "local_tf_session_args": {
      "intra_op_parallelism_threads": 8,
      "inter_op_parallelism_threads": 8
    },
    "env": "Supermarket",
    "env_config": {},
    "observation_space": null,
    "action_space": null,
    "env_task_fn": null,
    "render_env": false,
    "clip_rewards": null,
    "normalize_actions": true,
    "clip_actions": false,
    "disable_env_checking": false,
    "is_atari": false,
    "auto_wrap_old_gym_envs": true,
    "num_envs_per_worker": 1,
    "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>",
    "sample_async": false,
    "enable_connectors": true,
    "rollout_fragment_length": "auto",
    "batch_mode": "truncate_episodes",
    "remote_worker_envs": false,
    "remote_env_batch_wait_ms": 0,
    "validate_workers_after_construction": true,
    "preprocessor_pref": "deepmind",
    "observation_filter": "NoFilter",
    "synchronize_filters": true,
    "compress_observations": false,
    "enable_tf1_exec_eagerly": false,
    "sampler_perf_stats_ema_coef": null,
    "gamma": 0.9,
    "lr": 0.001,
    "train_batch_size": 4000,
    "model": {
      "_disable_preprocessor_api": false,
      "_disable_action_flattening": false,
      "fcnet_hiddens": [
        4,
        4
      ],
      "fcnet_activation": "tanh",
      "conv_filters": null,
      "conv_activation": "relu",
      "post_fcnet_hiddens": [],
      "post_fcnet_activation": "relu",
      "free_log_std": false,
      "no_final_linear": false,
      "vf_share_layers": false,
      "use_lstm": false,
      "max_seq_len": 20,
      "lstm_cell_size": 256,
      "lstm_use_prev_action": false,
      "lstm_use_prev_reward": false,
      "_time_major": false,
      "use_attention": false,
      "attention_num_transformer_units": 1,
      "attention_dim": 64,
      "attention_num_heads": 1,
      "attention_head_dim": 32,
      "attention_memory_inference": 50,
      "attention_memory_training": 50,
      "attention_position_wise_mlp_dim": 32,
      "attention_init_gru_gate_bias": 2.0,
      "attention_use_n_prev_actions": 0,
      "attention_use_n_prev_rewards": 0,
      "framestack": true,
      "dim": 84,
      "grayscale": false,
      "zero_mean": true,
      "custom_model": null,
      "custom_model_config": {},
      "custom_action_dist": null,
      "custom_preprocessor": null,
      "encoder_latent_dim": null,
      "lstm_use_prev_action_reward": -1,
      "_use_default_native_models": -1
    },
    "optimizer": {},
    "max_requests_in_flight_per_sampler_worker": 2,
    "learner_class": null,
    "_enable_learner_api": false,
    "_learner_hps": "PPOLearnerHPs(kl_coeff=0.2, kl_target=0.01, use_critic=True, clip_param=0.3, vf_clip_param=10.0, entropy_coeff=0.0, vf_loss_coeff=1.0, lr_schedule=None, entropy_coeff_schedule=None)",
    "explore": true,
    "exploration_config": {
      "type": "StochasticSampling"
    },
    "policy_states_are_swappable": false,
    "input_config": {},
    "actions_in_input_normalized": false,
    "postprocess_inputs": false,
    "shuffle_buffer_size": 0,
    "output": null,
    "output_config": {},
    "output_compress_columns": [
      "obs",
      "new_obs"
    ],
    "output_max_file_size": 67108864,
    "offline_sampling": false,
    "evaluation_interval": 1,
    "evaluation_duration": 10,
    "evaluation_duration_unit": "episodes",
    "evaluation_sample_timeout_s": 180.0,
    "evaluation_parallel_to_training": false,
    "evaluation_config": null,
    "off_policy_estimation_methods": {},
    "ope_split_batch_by_episode": true,
    "evaluation_num_workers": 1,
    "always_attach_evaluation_results": false,
    "enable_async_evaluation": false,
    "in_evaluation": false,
    "sync_filters_on_rollout_workers_timeout_s": 60.0,
    "keep_per_episode_custom_metrics": false,
    "metrics_episode_collection_timeout_s": 60.0,
    "metrics_num_episodes_for_smoothing": 100,
    "min_time_s_per_iteration": null,
    "min_train_timesteps_per_iteration": 0,
    "min_sample_timesteps_per_iteration": 0,
    "export_native_model_files": false,
    "checkpoint_trainable_policies_only": false,
    "logger_creator": null,
    "logger_config": null,
    "log_level": "WARN",
    "log_sys_usage": true,
    "fake_sampler": false,
    "seed": null,
    "worker_cls": null,
    "ignore_worker_failures": false,
    "recreate_failed_workers": false,
    "max_num_worker_restarts": 1000,
    "delay_between_worker_restarts_s": 60.0,
    "restart_failed_sub_environments": false,
    "num_consecutive_worker_failures_tolerance": 100,
    "worker_health_probe_timeout_s": 60,
    "worker_restore_timeout_s": 1800,
    "rl_module_spec": null,
    "_enable_rl_module_api": false,
    "_validate_exploration_conf_and_rl_modules": true,
    "_tf_policy_handles_more_than_one_loss": false,
    "_disable_preprocessor_api": false,
    "_disable_action_flattening": false,
    "_disable_execution_plan_api": true,
    "simple_optimizer": true,
    "replay_sequence_length": null,
    "horizon": -1,
    "soft_horizon": -1,
    "no_done_at_end": -1,
    "lr_schedule": null,
    "use_critic": true,
    "use_gae": true,
    "kl_coeff": 0.2,
    "sgd_minibatch_size": 128,
    "num_sgd_iter": 30,
    "shuffle_sequences": true,
    "vf_loss_coeff": 1.0,
    "entropy_coeff": 0.0,
    "entropy_coeff_schedule": null,
    "clip_param": 0.3,
    "vf_clip_param": 10.0,
    "grad_clip": null,
    "kl_target": 0.01,
    "vf_share_layers": -1,
    "__stdout_file__": null,
    "__stderr_file__": null,
    "lambda": 1.0,
    "input": "sampler",
    "multiagent": {
      "policies": {
        "default_policy": [
          null,
          null,
          null,
          null
        ]
      },
      "policy_mapping_fn": "<function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x28f7c7ac0>",
      "policies_to_train": null,
      "policy_map_capacity": 100,
      "policy_map_cache": -1,
      "count_steps_by": "env_steps",
      "observation_fn": null
    },
    "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>",
    "create_env_on_driver": false,
    "custom_eval_function": null,
    "framework": "tf2",
    "num_cpus_for_driver": 1,
    "num_workers": 1
  },
  "time_since_restore": 474.4024751186371,
  "iterations_since_restore": 6,
  "perf": {
    "cpu_util_percent": 45.4705357142857,
    "ram_util_percent": 76.47232142857142
  }
}
{
  "evaluation": {
    "episode_reward_max": 10.0,
    "episode_reward_min": -122.0,
    "episode_reward_mean": -38.4,
    "episode_len_mean": 76.0,
    "episode_media": {},
    "episodes_this_iter": 10,
    "policy_reward_min": {},
    "policy_reward_max": {},
    "policy_reward_mean": {},
    "custom_metrics": {},
    "hist_stats": {
      "episode_reward": [
        10.0,
        -56.0,
        -78.0,
        -23.0,
        -1.0,
        -34.0,
        -1.0,
        -78.0,
        -122.0,
        -1.0
      ],
      "episode_lengths": [
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76
      ]
    },
    "sampler_perf": {
      "mean_raw_obs_processing_ms": 0.1727907399086324,
      "mean_inference_ms": 9.241826326814365,
      "mean_action_processing_ms": 0.07783436860341009,
      "mean_env_wait_ms": 0.038918506111155056,
      "mean_env_render_ms": 0.0
    },
    "num_faulty_episodes": 0,
    "connector_metrics": {
      "ObsPreprocessorConnector_ms": 0.004267692565917969,
      "StateBufferConnector_ms": 0.002510547637939453,
      "ViewRequirementAgentConnector_ms": 0.07637500762939453
    },
    "num_agent_steps_sampled_this_iter": 760,
    "num_env_steps_sampled_this_iter": 760,
    "timesteps_this_iter": 760,
    "num_healthy_workers": 1,
    "num_in_flight_async_reqs": 0,
    "num_remote_worker_restarts": 0
  },
  "custom_metrics": {},
  "episode_media": {},
  "info": {
    "learner": {
      "default_policy": {
        "learner_stats": {
          "cur_kl_coeff": 0.44999998807907104,
          "cur_lr": 0.0010000000474974513,
          "total_loss": 8.086292266845703,
          "policy_loss": -0.008810899220407009,
          "vf_loss": 8.091378211975098,
          "vf_explained_var": -0.0007903702207840979,
          "kl": 0.008278110064566135,
          "entropy": 2.8703150749206543,
          "entropy_coeff": 0.0
        },
        "custom_metrics": {},
        "num_agent_steps_trained": 125.0,
        "num_grad_updates_lifetime": 6240.5,
        "diff_num_grad_updates_vs_sampler_policy": 479.5
      }
    },
    "num_env_steps_sampled": 28000,
    "num_env_steps_trained": 28000,
    "num_agent_steps_sampled": 28000,
    "num_agent_steps_trained": 28000
  },
  "sampler_results": {
    "episode_reward_max": 65.0,
    "episode_reward_min": -155.0,
    "episode_reward_mean": -7.22,
    "episode_len_mean": 76.0,
    "episode_media": {},
    "episodes_this_iter": 53,
    "policy_reward_min": {},
    "policy_reward_max": {},
    "policy_reward_mean": {},
    "custom_metrics": {},
    "hist_stats": {
      "episode_reward": [
        21.0,
        54.0,
        21.0,
        54.0,
        10.0,
        54.0,
        10.0,
        -12.0,
        -23.0,
        -23.0,
        -1.0,
        -12.0,
        -23.0,
        -45.0,
        -23.0,
        -34.0,
        21.0,
        32.0,
        54.0,
        54.0,
        -23.0,
        32.0,
        -12.0,
        -34.0,
        65.0,
        -12.0,
        -34.0,
        32.0,
        -45.0,
        21.0,
        -23.0,
        -34.0,
        10.0,
        10.0,
        10.0,
        32.0,
        -1.0,
        43.0,
        21.0,
        65.0,
        32.0,
        -12.0,
        10.0,
        10.0,
        32.0,
        21.0,
        54.0,
        32.0,
        21.0,
        -12.0,
        -56.0,
        -155.0,
        -56.0,
        -34.0,
        -56.0,
        -122.0,
        10.0,
        -23.0,
        -45.0,
        -1.0,
        10.0,
        -23.0,
        -45.0,
        -122.0,
        -67.0,
        -78.0,
        -89.0,
        -73.0,
        -67.0,
        -56.0,
        -56.0,
        54.0,
        -23.0,
        -45.0,
        -78.0,
        -23.0,
        21.0,
        21.0,
        -23.0,
        -1.0,
        32.0,
        -1.0,
        32.0,
        21.0,
        21.0,
        54.0,
        54.0,
        43.0,
        -45.0,
        54.0,
        -23.0,
        -12.0,
        -89.0,
        -78.0,
        -23.0,
        -12.0,
        -1.0,
        10.0,
        65.0,
        -23.0
      ],
      "episode_lengths": [
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76
      ]
    },
    "sampler_perf": {
      "mean_raw_obs_processing_ms": 0.1876651654424885,
      "mean_inference_ms": 9.255768525547246,
      "mean_action_processing_ms": 0.07790136666160631,
      "mean_env_wait_ms": 0.03685529966781364,
      "mean_env_render_ms": 0.0
    },
    "num_faulty_episodes": 0,
    "connector_metrics": {
      "ObsPreprocessorConnector_ms": 0.004649639129638672,
      "StateBufferConnector_ms": 0.0028793811798095703,
      "ViewRequirementAgentConnector_ms": 0.08601808547973633
    }
  },
  "episode_reward_max": 65.0,
  "episode_reward_min": -155.0,
  "episode_reward_mean": -7.22,
  "episode_len_mean": 76.0,
  "episodes_this_iter": 53,
  "policy_reward_min": {},
  "policy_reward_max": {},
  "policy_reward_mean": {},
  "hist_stats": {
    "episode_reward": [
      21.0,
      54.0,
      21.0,
      54.0,
      10.0,
      54.0,
      10.0,
      -12.0,
      -23.0,
      -23.0,
      -1.0,
      -12.0,
      -23.0,
      -45.0,
      -23.0,
      -34.0,
      21.0,
      32.0,
      54.0,
      54.0,
      -23.0,
      32.0,
      -12.0,
      -34.0,
      65.0,
      -12.0,
      -34.0,
      32.0,
      -45.0,
      21.0,
      -23.0,
      -34.0,
      10.0,
      10.0,
      10.0,
      32.0,
      -1.0,
      43.0,
      21.0,
      65.0,
      32.0,
      -12.0,
      10.0,
      10.0,
      32.0,
      21.0,
      54.0,
      32.0,
      21.0,
      -12.0,
      -56.0,
      -155.0,
      -56.0,
      -34.0,
      -56.0,
      -122.0,
      10.0,
      -23.0,
      -45.0,
      -1.0,
      10.0,
      -23.0,
      -45.0,
      -122.0,
      -67.0,
      -78.0,
      -89.0,
      -73.0,
      -67.0,
      -56.0,
      -56.0,
      54.0,
      -23.0,
      -45.0,
      -78.0,
      -23.0,
      21.0,
      21.0,
      -23.0,
      -1.0,
      32.0,
      -1.0,
      32.0,
      21.0,
      21.0,
      54.0,
      54.0,
      43.0,
      -45.0,
      54.0,
      -23.0,
      -12.0,
      -89.0,
      -78.0,
      -23.0,
      -12.0,
      -1.0,
      10.0,
      65.0,
      -23.0
    ],
    "episode_lengths": [
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76
    ]
  },
  "sampler_perf": {
    "mean_raw_obs_processing_ms": 0.1876651654424885,
    "mean_inference_ms": 9.255768525547246,
    "mean_action_processing_ms": 0.07790136666160631,
    "mean_env_wait_ms": 0.03685529966781364,
    "mean_env_render_ms": 0.0
  },
  "num_faulty_episodes": 0,
  "connector_metrics": {
    "ObsPreprocessorConnector_ms": 0.004649639129638672,
    "StateBufferConnector_ms": 0.0028793811798095703,
    "ViewRequirementAgentConnector_ms": 0.08601808547973633
  },
  "num_healthy_workers": 1,
  "num_in_flight_async_reqs": 0,
  "num_remote_worker_restarts": 0,
  "num_agent_steps_sampled": 28000,
  "num_agent_steps_trained": 28000,
  "num_env_steps_sampled": 28000,
  "num_env_steps_trained": 28000,
  "num_env_steps_sampled_this_iter": 4000,
  "num_env_steps_trained_this_iter": 4000,
  "timesteps_total": 28000,
  "num_steps_trained_this_iter": 4000,
  "agent_timesteps_total": 28000,
  "timers": {
    "training_iteration_time_ms": 71732.648,
    "sample_time_ms": 38350.493,
    "learn_time_ms": 33374.33,
    "learn_throughput": 119.853,
    "synch_weights_time_ms": 7.061
  },
  "counters": {
    "num_env_steps_sampled": 28000,
    "num_env_steps_trained": 28000,
    "num_agent_steps_sampled": 28000,
    "num_agent_steps_trained": 28000
  },
  "done": false,
  "episodes_total": 368,
  "training_iteration": 7,
  "trial_id": "b0a0c_00000",
  "date": "2023-05-31_15-52-34",
  "timestamp": 1685537554,
  "time_this_iter_s": 78.78652691841125,
  "time_total_s": 553.1890020370483,
  "pid": 48728,
  "hostname": "Ozans-MacBook-Pro.local",
  "node_ip": "127.0.0.1",
  "config": {
    "extra_python_environs_for_driver": {},
    "extra_python_environs_for_worker": {},
    "num_gpus": 0,
    "num_cpus_per_worker": 1,
    "num_gpus_per_worker": 0,
    "_fake_gpus": false,
    "num_learner_workers": 0,
    "num_gpus_per_learner_worker": 0,
    "num_cpus_per_learner_worker": 1,
    "local_gpu_idx": 0,
    "custom_resources_per_worker": {},
    "placement_strategy": "PACK",
    "eager_tracing": false,
    "eager_max_retraces": 20,
    "tf_session_args": {
      "intra_op_parallelism_threads": 2,
      "inter_op_parallelism_threads": 2,
      "gpu_options": {
        "allow_growth": true
      },
      "log_device_placement": false,
      "device_count": {
        "CPU": 1
      },
      "allow_soft_placement": true
    },
    "local_tf_session_args": {
      "intra_op_parallelism_threads": 8,
      "inter_op_parallelism_threads": 8
    },
    "env": "Supermarket",
    "env_config": {},
    "observation_space": null,
    "action_space": null,
    "env_task_fn": null,
    "render_env": false,
    "clip_rewards": null,
    "normalize_actions": true,
    "clip_actions": false,
    "disable_env_checking": false,
    "is_atari": false,
    "auto_wrap_old_gym_envs": true,
    "num_envs_per_worker": 1,
    "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>",
    "sample_async": false,
    "enable_connectors": true,
    "rollout_fragment_length": "auto",
    "batch_mode": "truncate_episodes",
    "remote_worker_envs": false,
    "remote_env_batch_wait_ms": 0,
    "validate_workers_after_construction": true,
    "preprocessor_pref": "deepmind",
    "observation_filter": "NoFilter",
    "synchronize_filters": true,
    "compress_observations": false,
    "enable_tf1_exec_eagerly": false,
    "sampler_perf_stats_ema_coef": null,
    "gamma": 0.9,
    "lr": 0.001,
    "train_batch_size": 4000,
    "model": {
      "_disable_preprocessor_api": false,
      "_disable_action_flattening": false,
      "fcnet_hiddens": [
        4,
        4
      ],
      "fcnet_activation": "tanh",
      "conv_filters": null,
      "conv_activation": "relu",
      "post_fcnet_hiddens": [],
      "post_fcnet_activation": "relu",
      "free_log_std": false,
      "no_final_linear": false,
      "vf_share_layers": false,
      "use_lstm": false,
      "max_seq_len": 20,
      "lstm_cell_size": 256,
      "lstm_use_prev_action": false,
      "lstm_use_prev_reward": false,
      "_time_major": false,
      "use_attention": false,
      "attention_num_transformer_units": 1,
      "attention_dim": 64,
      "attention_num_heads": 1,
      "attention_head_dim": 32,
      "attention_memory_inference": 50,
      "attention_memory_training": 50,
      "attention_position_wise_mlp_dim": 32,
      "attention_init_gru_gate_bias": 2.0,
      "attention_use_n_prev_actions": 0,
      "attention_use_n_prev_rewards": 0,
      "framestack": true,
      "dim": 84,
      "grayscale": false,
      "zero_mean": true,
      "custom_model": null,
      "custom_model_config": {},
      "custom_action_dist": null,
      "custom_preprocessor": null,
      "encoder_latent_dim": null,
      "lstm_use_prev_action_reward": -1,
      "_use_default_native_models": -1
    },
    "optimizer": {},
    "max_requests_in_flight_per_sampler_worker": 2,
    "learner_class": null,
    "_enable_learner_api": false,
    "_learner_hps": "PPOLearnerHPs(kl_coeff=0.2, kl_target=0.01, use_critic=True, clip_param=0.3, vf_clip_param=10.0, entropy_coeff=0.0, vf_loss_coeff=1.0, lr_schedule=None, entropy_coeff_schedule=None)",
    "explore": true,
    "exploration_config": {
      "type": "StochasticSampling"
    },
    "policy_states_are_swappable": false,
    "input_config": {},
    "actions_in_input_normalized": false,
    "postprocess_inputs": false,
    "shuffle_buffer_size": 0,
    "output": null,
    "output_config": {},
    "output_compress_columns": [
      "obs",
      "new_obs"
    ],
    "output_max_file_size": 67108864,
    "offline_sampling": false,
    "evaluation_interval": 1,
    "evaluation_duration": 10,
    "evaluation_duration_unit": "episodes",
    "evaluation_sample_timeout_s": 180.0,
    "evaluation_parallel_to_training": false,
    "evaluation_config": null,
    "off_policy_estimation_methods": {},
    "ope_split_batch_by_episode": true,
    "evaluation_num_workers": 1,
    "always_attach_evaluation_results": false,
    "enable_async_evaluation": false,
    "in_evaluation": false,
    "sync_filters_on_rollout_workers_timeout_s": 60.0,
    "keep_per_episode_custom_metrics": false,
    "metrics_episode_collection_timeout_s": 60.0,
    "metrics_num_episodes_for_smoothing": 100,
    "min_time_s_per_iteration": null,
    "min_train_timesteps_per_iteration": 0,
    "min_sample_timesteps_per_iteration": 0,
    "export_native_model_files": false,
    "checkpoint_trainable_policies_only": false,
    "logger_creator": null,
    "logger_config": null,
    "log_level": "WARN",
    "log_sys_usage": true,
    "fake_sampler": false,
    "seed": null,
    "worker_cls": null,
    "ignore_worker_failures": false,
    "recreate_failed_workers": false,
    "max_num_worker_restarts": 1000,
    "delay_between_worker_restarts_s": 60.0,
    "restart_failed_sub_environments": false,
    "num_consecutive_worker_failures_tolerance": 100,
    "worker_health_probe_timeout_s": 60,
    "worker_restore_timeout_s": 1800,
    "rl_module_spec": null,
    "_enable_rl_module_api": false,
    "_validate_exploration_conf_and_rl_modules": true,
    "_tf_policy_handles_more_than_one_loss": false,
    "_disable_preprocessor_api": false,
    "_disable_action_flattening": false,
    "_disable_execution_plan_api": true,
    "simple_optimizer": true,
    "replay_sequence_length": null,
    "horizon": -1,
    "soft_horizon": -1,
    "no_done_at_end": -1,
    "lr_schedule": null,
    "use_critic": true,
    "use_gae": true,
    "kl_coeff": 0.2,
    "sgd_minibatch_size": 128,
    "num_sgd_iter": 30,
    "shuffle_sequences": true,
    "vf_loss_coeff": 1.0,
    "entropy_coeff": 0.0,
    "entropy_coeff_schedule": null,
    "clip_param": 0.3,
    "vf_clip_param": 10.0,
    "grad_clip": null,
    "kl_target": 0.01,
    "vf_share_layers": -1,
    "__stdout_file__": null,
    "__stderr_file__": null,
    "lambda": 1.0,
    "input": "sampler",
    "multiagent": {
      "policies": {
        "default_policy": [
          null,
          null,
          null,
          null
        ]
      },
      "policy_mapping_fn": "<function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x28f7c7ac0>",
      "policies_to_train": null,
      "policy_map_capacity": 100,
      "policy_map_cache": -1,
      "count_steps_by": "env_steps",
      "observation_fn": null
    },
    "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>",
    "create_env_on_driver": false,
    "custom_eval_function": null,
    "framework": "tf2",
    "num_cpus_for_driver": 1,
    "num_workers": 1
  },
  "time_since_restore": 553.1890020370483,
  "iterations_since_restore": 7,
  "perf": {
    "cpu_util_percent": 42.80363636363638,
    "ram_util_percent": 75.9172727272727
  }
}
{
  "evaluation": {
    "episode_reward_max": 54.0,
    "episode_reward_min": -67.0,
    "episode_reward_mean": 5.6,
    "episode_len_mean": 76.0,
    "episode_media": {},
    "episodes_this_iter": 10,
    "policy_reward_min": {},
    "policy_reward_max": {},
    "policy_reward_mean": {},
    "custom_metrics": {},
    "hist_stats": {
      "episode_reward": [
        54.0,
        21.0,
        -12.0,
        -12.0,
        -12.0,
        32.0,
        54.0,
        10.0,
        -67.0,
        -12.0
      ],
      "episode_lengths": [
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76
      ]
    },
    "sampler_perf": {
      "mean_raw_obs_processing_ms": 0.17212343302198077,
      "mean_inference_ms": 9.23211063685493,
      "mean_action_processing_ms": 0.07745918132152786,
      "mean_env_wait_ms": 0.03861981068683129,
      "mean_env_render_ms": 0.0
    },
    "num_faulty_episodes": 0,
    "connector_metrics": {
      "ObsPreprocessorConnector_ms": 0.0045490264892578125,
      "StateBufferConnector_ms": 0.00293731689453125,
      "ViewRequirementAgentConnector_ms": 0.08127212524414062
    },
    "num_agent_steps_sampled_this_iter": 760,
    "num_env_steps_sampled_this_iter": 760,
    "timesteps_this_iter": 760,
    "num_healthy_workers": 1,
    "num_in_flight_async_reqs": 0,
    "num_remote_worker_restarts": 0
  },
  "custom_metrics": {},
  "episode_media": {},
  "info": {
    "learner": {
      "default_policy": {
        "learner_stats": {
          "cur_kl_coeff": 0.44999998807907104,
          "cur_lr": 0.0010000000474974513,
          "total_loss": 7.33642053604126,
          "policy_loss": -0.012871498242020607,
          "vf_loss": 7.344870090484619,
          "vf_explained_var": -0.0025892488192766905,
          "kl": 0.009828854352235794,
          "entropy": 2.8560101985931396,
          "entropy_coeff": 0.0
        },
        "custom_metrics": {},
        "num_agent_steps_trained": 125.0,
        "num_grad_updates_lifetime": 7200.5,
        "diff_num_grad_updates_vs_sampler_policy": 479.5
      }
    },
    "num_env_steps_sampled": 32000,
    "num_env_steps_trained": 32000,
    "num_agent_steps_sampled": 32000,
    "num_agent_steps_trained": 32000
  },
  "sampler_results": {
    "episode_reward_max": 65.0,
    "episode_reward_min": -122.0,
    "episode_reward_mean": -8.93,
    "episode_len_mean": 76.0,
    "episode_media": {},
    "episodes_this_iter": 53,
    "policy_reward_min": {},
    "policy_reward_max": {},
    "policy_reward_mean": {},
    "custom_metrics": {},
    "hist_stats": {
      "episode_reward": [
        -34.0,
        -56.0,
        -122.0,
        10.0,
        -23.0,
        -45.0,
        -1.0,
        10.0,
        -23.0,
        -45.0,
        -122.0,
        -67.0,
        -78.0,
        -89.0,
        -73.0,
        -67.0,
        -56.0,
        -56.0,
        54.0,
        -23.0,
        -45.0,
        -78.0,
        -23.0,
        21.0,
        21.0,
        -23.0,
        -1.0,
        32.0,
        -1.0,
        32.0,
        21.0,
        21.0,
        54.0,
        54.0,
        43.0,
        -45.0,
        54.0,
        -23.0,
        -12.0,
        -89.0,
        -78.0,
        -23.0,
        -12.0,
        -1.0,
        10.0,
        65.0,
        -23.0,
        -89.0,
        -56.0,
        10.0,
        -12.0,
        32.0,
        43.0,
        -1.0,
        -45.0,
        32.0,
        54.0,
        21.0,
        21.0,
        -23.0,
        -1.0,
        -89.0,
        -89.0,
        10.0,
        -78.0,
        -45.0,
        -56.0,
        -1.0,
        43.0,
        54.0,
        21.0,
        -89.0,
        -1.0,
        21.0,
        32.0,
        54.0,
        -1.0,
        54.0,
        -23.0,
        43.0,
        10.0,
        65.0,
        15.0,
        -1.0,
        32.0,
        21.0,
        -12.0,
        10.0,
        -34.0,
        43.0,
        -12.0,
        65.0,
        32.0,
        21.0,
        21.0,
        -1.0,
        -45.0,
        -45.0,
        10.0,
        21.0
      ],
      "episode_lengths": [
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76
      ]
    },
    "sampler_perf": {
      "mean_raw_obs_processing_ms": 0.18743529957497884,
      "mean_inference_ms": 9.272577670485832,
      "mean_action_processing_ms": 0.07785067455491297,
      "mean_env_wait_ms": 0.036742624276629485,
      "mean_env_render_ms": 0.0
    },
    "num_faulty_episodes": 0,
    "connector_metrics": {
      "ObsPreprocessorConnector_ms": 0.004429817199707031,
      "StateBufferConnector_ms": 0.0028204917907714844,
      "ViewRequirementAgentConnector_ms": 0.08248305320739746
    }
  },
  "episode_reward_max": 65.0,
  "episode_reward_min": -122.0,
  "episode_reward_mean": -8.93,
  "episode_len_mean": 76.0,
  "episodes_this_iter": 53,
  "policy_reward_min": {},
  "policy_reward_max": {},
  "policy_reward_mean": {},
  "hist_stats": {
    "episode_reward": [
      -34.0,
      -56.0,
      -122.0,
      10.0,
      -23.0,
      -45.0,
      -1.0,
      10.0,
      -23.0,
      -45.0,
      -122.0,
      -67.0,
      -78.0,
      -89.0,
      -73.0,
      -67.0,
      -56.0,
      -56.0,
      54.0,
      -23.0,
      -45.0,
      -78.0,
      -23.0,
      21.0,
      21.0,
      -23.0,
      -1.0,
      32.0,
      -1.0,
      32.0,
      21.0,
      21.0,
      54.0,
      54.0,
      43.0,
      -45.0,
      54.0,
      -23.0,
      -12.0,
      -89.0,
      -78.0,
      -23.0,
      -12.0,
      -1.0,
      10.0,
      65.0,
      -23.0,
      -89.0,
      -56.0,
      10.0,
      -12.0,
      32.0,
      43.0,
      -1.0,
      -45.0,
      32.0,
      54.0,
      21.0,
      21.0,
      -23.0,
      -1.0,
      -89.0,
      -89.0,
      10.0,
      -78.0,
      -45.0,
      -56.0,
      -1.0,
      43.0,
      54.0,
      21.0,
      -89.0,
      -1.0,
      21.0,
      32.0,
      54.0,
      -1.0,
      54.0,
      -23.0,
      43.0,
      10.0,
      65.0,
      15.0,
      -1.0,
      32.0,
      21.0,
      -12.0,
      10.0,
      -34.0,
      43.0,
      -12.0,
      65.0,
      32.0,
      21.0,
      21.0,
      -1.0,
      -45.0,
      -45.0,
      10.0,
      21.0
    ],
    "episode_lengths": [
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76
    ]
  },
  "sampler_perf": {
    "mean_raw_obs_processing_ms": 0.18743529957497884,
    "mean_inference_ms": 9.272577670485832,
    "mean_action_processing_ms": 0.07785067455491297,
    "mean_env_wait_ms": 0.036742624276629485,
    "mean_env_render_ms": 0.0
  },
  "num_faulty_episodes": 0,
  "connector_metrics": {
    "ObsPreprocessorConnector_ms": 0.004429817199707031,
    "StateBufferConnector_ms": 0.0028204917907714844,
    "ViewRequirementAgentConnector_ms": 0.08248305320739746
  },
  "num_healthy_workers": 1,
  "num_in_flight_async_reqs": 0,
  "num_remote_worker_restarts": 0,
  "num_agent_steps_sampled": 32000,
  "num_agent_steps_trained": 32000,
  "num_env_steps_sampled": 32000,
  "num_env_steps_trained": 32000,
  "num_env_steps_sampled_this_iter": 4000,
  "num_env_steps_trained_this_iter": 4000,
  "timesteps_total": 32000,
  "num_steps_trained_this_iter": 4000,
  "agent_timesteps_total": 32000,
  "timers": {
    "training_iteration_time_ms": 71591.829,
    "sample_time_ms": 38326.645,
    "learn_time_ms": 33257.512,
    "learn_throughput": 120.274,
    "synch_weights_time_ms": 6.95
  },
  "counters": {
    "num_env_steps_sampled": 32000,
    "num_env_steps_trained": 32000,
    "num_agent_steps_sampled": 32000,
    "num_agent_steps_trained": 32000
  },
  "done": false,
  "episodes_total": 421,
  "training_iteration": 8,
  "trial_id": "b0a0c_00000",
  "date": "2023-05-31_15-53-52",
  "timestamp": 1685537632,
  "time_this_iter_s": 77.82951998710632,
  "time_total_s": 631.0185220241547,
  "pid": 48728,
  "hostname": "Ozans-MacBook-Pro.local",
  "node_ip": "127.0.0.1",
  "config": {
    "extra_python_environs_for_driver": {},
    "extra_python_environs_for_worker": {},
    "num_gpus": 0,
    "num_cpus_per_worker": 1,
    "num_gpus_per_worker": 0,
    "_fake_gpus": false,
    "num_learner_workers": 0,
    "num_gpus_per_learner_worker": 0,
    "num_cpus_per_learner_worker": 1,
    "local_gpu_idx": 0,
    "custom_resources_per_worker": {},
    "placement_strategy": "PACK",
    "eager_tracing": false,
    "eager_max_retraces": 20,
    "tf_session_args": {
      "intra_op_parallelism_threads": 2,
      "inter_op_parallelism_threads": 2,
      "gpu_options": {
        "allow_growth": true
      },
      "log_device_placement": false,
      "device_count": {
        "CPU": 1
      },
      "allow_soft_placement": true
    },
    "local_tf_session_args": {
      "intra_op_parallelism_threads": 8,
      "inter_op_parallelism_threads": 8
    },
    "env": "Supermarket",
    "env_config": {},
    "observation_space": null,
    "action_space": null,
    "env_task_fn": null,
    "render_env": false,
    "clip_rewards": null,
    "normalize_actions": true,
    "clip_actions": false,
    "disable_env_checking": false,
    "is_atari": false,
    "auto_wrap_old_gym_envs": true,
    "num_envs_per_worker": 1,
    "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>",
    "sample_async": false,
    "enable_connectors": true,
    "rollout_fragment_length": "auto",
    "batch_mode": "truncate_episodes",
    "remote_worker_envs": false,
    "remote_env_batch_wait_ms": 0,
    "validate_workers_after_construction": true,
    "preprocessor_pref": "deepmind",
    "observation_filter": "NoFilter",
    "synchronize_filters": true,
    "compress_observations": false,
    "enable_tf1_exec_eagerly": false,
    "sampler_perf_stats_ema_coef": null,
    "gamma": 0.9,
    "lr": 0.001,
    "train_batch_size": 4000,
    "model": {
      "_disable_preprocessor_api": false,
      "_disable_action_flattening": false,
      "fcnet_hiddens": [
        4,
        4
      ],
      "fcnet_activation": "tanh",
      "conv_filters": null,
      "conv_activation": "relu",
      "post_fcnet_hiddens": [],
      "post_fcnet_activation": "relu",
      "free_log_std": false,
      "no_final_linear": false,
      "vf_share_layers": false,
      "use_lstm": false,
      "max_seq_len": 20,
      "lstm_cell_size": 256,
      "lstm_use_prev_action": false,
      "lstm_use_prev_reward": false,
      "_time_major": false,
      "use_attention": false,
      "attention_num_transformer_units": 1,
      "attention_dim": 64,
      "attention_num_heads": 1,
      "attention_head_dim": 32,
      "attention_memory_inference": 50,
      "attention_memory_training": 50,
      "attention_position_wise_mlp_dim": 32,
      "attention_init_gru_gate_bias": 2.0,
      "attention_use_n_prev_actions": 0,
      "attention_use_n_prev_rewards": 0,
      "framestack": true,
      "dim": 84,
      "grayscale": false,
      "zero_mean": true,
      "custom_model": null,
      "custom_model_config": {},
      "custom_action_dist": null,
      "custom_preprocessor": null,
      "encoder_latent_dim": null,
      "lstm_use_prev_action_reward": -1,
      "_use_default_native_models": -1
    },
    "optimizer": {},
    "max_requests_in_flight_per_sampler_worker": 2,
    "learner_class": null,
    "_enable_learner_api": false,
    "_learner_hps": "PPOLearnerHPs(kl_coeff=0.2, kl_target=0.01, use_critic=True, clip_param=0.3, vf_clip_param=10.0, entropy_coeff=0.0, vf_loss_coeff=1.0, lr_schedule=None, entropy_coeff_schedule=None)",
    "explore": true,
    "exploration_config": {
      "type": "StochasticSampling"
    },
    "policy_states_are_swappable": false,
    "input_config": {},
    "actions_in_input_normalized": false,
    "postprocess_inputs": false,
    "shuffle_buffer_size": 0,
    "output": null,
    "output_config": {},
    "output_compress_columns": [
      "obs",
      "new_obs"
    ],
    "output_max_file_size": 67108864,
    "offline_sampling": false,
    "evaluation_interval": 1,
    "evaluation_duration": 10,
    "evaluation_duration_unit": "episodes",
    "evaluation_sample_timeout_s": 180.0,
    "evaluation_parallel_to_training": false,
    "evaluation_config": null,
    "off_policy_estimation_methods": {},
    "ope_split_batch_by_episode": true,
    "evaluation_num_workers": 1,
    "always_attach_evaluation_results": false,
    "enable_async_evaluation": false,
    "in_evaluation": false,
    "sync_filters_on_rollout_workers_timeout_s": 60.0,
    "keep_per_episode_custom_metrics": false,
    "metrics_episode_collection_timeout_s": 60.0,
    "metrics_num_episodes_for_smoothing": 100,
    "min_time_s_per_iteration": null,
    "min_train_timesteps_per_iteration": 0,
    "min_sample_timesteps_per_iteration": 0,
    "export_native_model_files": false,
    "checkpoint_trainable_policies_only": false,
    "logger_creator": null,
    "logger_config": null,
    "log_level": "WARN",
    "log_sys_usage": true,
    "fake_sampler": false,
    "seed": null,
    "worker_cls": null,
    "ignore_worker_failures": false,
    "recreate_failed_workers": false,
    "max_num_worker_restarts": 1000,
    "delay_between_worker_restarts_s": 60.0,
    "restart_failed_sub_environments": false,
    "num_consecutive_worker_failures_tolerance": 100,
    "worker_health_probe_timeout_s": 60,
    "worker_restore_timeout_s": 1800,
    "rl_module_spec": null,
    "_enable_rl_module_api": false,
    "_validate_exploration_conf_and_rl_modules": true,
    "_tf_policy_handles_more_than_one_loss": false,
    "_disable_preprocessor_api": false,
    "_disable_action_flattening": false,
    "_disable_execution_plan_api": true,
    "simple_optimizer": true,
    "replay_sequence_length": null,
    "horizon": -1,
    "soft_horizon": -1,
    "no_done_at_end": -1,
    "lr_schedule": null,
    "use_critic": true,
    "use_gae": true,
    "kl_coeff": 0.2,
    "sgd_minibatch_size": 128,
    "num_sgd_iter": 30,
    "shuffle_sequences": true,
    "vf_loss_coeff": 1.0,
    "entropy_coeff": 0.0,
    "entropy_coeff_schedule": null,
    "clip_param": 0.3,
    "vf_clip_param": 10.0,
    "grad_clip": null,
    "kl_target": 0.01,
    "vf_share_layers": -1,
    "__stdout_file__": null,
    "__stderr_file__": null,
    "lambda": 1.0,
    "input": "sampler",
    "multiagent": {
      "policies": {
        "default_policy": [
          null,
          null,
          null,
          null
        ]
      },
      "policy_mapping_fn": "<function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x28f7c7ac0>",
      "policies_to_train": null,
      "policy_map_capacity": 100,
      "policy_map_cache": -1,
      "count_steps_by": "env_steps",
      "observation_fn": null
    },
    "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>",
    "create_env_on_driver": false,
    "custom_eval_function": null,
    "framework": "tf2",
    "num_cpus_for_driver": 1,
    "num_workers": 1
  },
  "time_since_restore": 631.0185220241547,
  "iterations_since_restore": 8,
  "perf": {
    "cpu_util_percent": 40.64220183486239,
    "ram_util_percent": 73.77339449541283
  }
}
{
  "evaluation": {
    "episode_reward_max": 65.0,
    "episode_reward_min": -34.0,
    "episode_reward_mean": 22.1,
    "episode_len_mean": 76.0,
    "episode_media": {},
    "episodes_this_iter": 10,
    "policy_reward_min": {},
    "policy_reward_max": {},
    "policy_reward_mean": {},
    "custom_metrics": {},
    "hist_stats": {
      "episode_reward": [
        21.0,
        54.0,
        10.0,
        21.0,
        -34.0,
        54.0,
        -12.0,
        -23.0,
        65.0,
        65.0
      ],
      "episode_lengths": [
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76
      ]
    },
    "sampler_perf": {
      "mean_raw_obs_processing_ms": 0.17146861373707314,
      "mean_inference_ms": 9.214029833511065,
      "mean_action_processing_ms": 0.0770440873234022,
      "mean_env_wait_ms": 0.038311331963228945,
      "mean_env_render_ms": 0.0
    },
    "num_faulty_episodes": 0,
    "connector_metrics": {
      "ObsPreprocessorConnector_ms": 0.004184246063232422,
      "StateBufferConnector_ms": 0.002536773681640625,
      "ViewRequirementAgentConnector_ms": 0.07937192916870117
    },
    "num_agent_steps_sampled_this_iter": 760,
    "num_env_steps_sampled_this_iter": 760,
    "timesteps_this_iter": 760,
    "num_healthy_workers": 1,
    "num_in_flight_async_reqs": 0,
    "num_remote_worker_restarts": 0
  },
  "custom_metrics": {},
  "episode_media": {},
  "info": {
    "learner": {
      "default_policy": {
        "learner_stats": {
          "cur_kl_coeff": 0.44999998807907104,
          "cur_lr": 0.0010000000474974513,
          "total_loss": 7.379505634307861,
          "policy_loss": -0.018150044605135918,
          "vf_loss": 7.391454219818115,
          "vf_explained_var": 0.01193331740796566,
          "kl": 0.013781381770968437,
          "entropy": 2.8313164710998535,
          "entropy_coeff": 0.0
        },
        "custom_metrics": {},
        "num_agent_steps_trained": 125.0,
        "num_grad_updates_lifetime": 8160.5,
        "diff_num_grad_updates_vs_sampler_policy": 479.5
      }
    },
    "num_env_steps_sampled": 36000,
    "num_env_steps_trained": 36000,
    "num_agent_steps_sampled": 36000,
    "num_agent_steps_trained": 36000
  },
  "sampler_results": {
    "episode_reward_max": 76.0,
    "episode_reward_min": -89.0,
    "episode_reward_mean": 3.39,
    "episode_len_mean": 76.0,
    "episode_media": {},
    "episodes_this_iter": 52,
    "policy_reward_min": {},
    "policy_reward_max": {},
    "policy_reward_mean": {},
    "custom_metrics": {},
    "hist_stats": {
      "episode_reward": [
        43.0,
        -1.0,
        -45.0,
        32.0,
        54.0,
        21.0,
        21.0,
        -23.0,
        -1.0,
        -89.0,
        -89.0,
        10.0,
        -78.0,
        -45.0,
        -56.0,
        -1.0,
        43.0,
        54.0,
        21.0,
        -89.0,
        -1.0,
        21.0,
        32.0,
        54.0,
        -1.0,
        54.0,
        -23.0,
        43.0,
        10.0,
        65.0,
        15.0,
        -1.0,
        32.0,
        21.0,
        -12.0,
        10.0,
        -34.0,
        43.0,
        -12.0,
        65.0,
        32.0,
        21.0,
        21.0,
        -1.0,
        -45.0,
        -45.0,
        10.0,
        21.0,
        32.0,
        -67.0,
        -78.0,
        -23.0,
        10.0,
        21.0,
        -12.0,
        -12.0,
        43.0,
        -34.0,
        -45.0,
        10.0,
        -23.0,
        65.0,
        10.0,
        -1.0,
        10.0,
        10.0,
        32.0,
        -1.0,
        -1.0,
        32.0,
        -67.0,
        10.0,
        32.0,
        43.0,
        21.0,
        21.0,
        -56.0,
        -45.0,
        -45.0,
        -56.0,
        -12.0,
        -34.0,
        32.0,
        76.0,
        -1.0,
        21.0,
        43.0,
        65.0,
        65.0,
        10.0,
        65.0,
        -34.0,
        -12.0,
        21.0,
        54.0,
        26.0,
        -23.0,
        21.0,
        10.0,
        -67.0
      ],
      "episode_lengths": [
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76
      ]
    },
    "sampler_perf": {
      "mean_raw_obs_processing_ms": 0.18698310904380072,
      "mean_inference_ms": 9.267812751512055,
      "mean_action_processing_ms": 0.07771383237859038,
      "mean_env_wait_ms": 0.03659776078961663,
      "mean_env_render_ms": 0.0
    },
    "num_faulty_episodes": 0,
    "connector_metrics": {
      "ObsPreprocessorConnector_ms": 0.004250288009643555,
      "StateBufferConnector_ms": 0.002818584442138672,
      "ViewRequirementAgentConnector_ms": 0.08105182647705078
    }
  },
  "episode_reward_max": 76.0,
  "episode_reward_min": -89.0,
  "episode_reward_mean": 3.39,
  "episode_len_mean": 76.0,
  "episodes_this_iter": 52,
  "policy_reward_min": {},
  "policy_reward_max": {},
  "policy_reward_mean": {},
  "hist_stats": {
    "episode_reward": [
      43.0,
      -1.0,
      -45.0,
      32.0,
      54.0,
      21.0,
      21.0,
      -23.0,
      -1.0,
      -89.0,
      -89.0,
      10.0,
      -78.0,
      -45.0,
      -56.0,
      -1.0,
      43.0,
      54.0,
      21.0,
      -89.0,
      -1.0,
      21.0,
      32.0,
      54.0,
      -1.0,
      54.0,
      -23.0,
      43.0,
      10.0,
      65.0,
      15.0,
      -1.0,
      32.0,
      21.0,
      -12.0,
      10.0,
      -34.0,
      43.0,
      -12.0,
      65.0,
      32.0,
      21.0,
      21.0,
      -1.0,
      -45.0,
      -45.0,
      10.0,
      21.0,
      32.0,
      -67.0,
      -78.0,
      -23.0,
      10.0,
      21.0,
      -12.0,
      -12.0,
      43.0,
      -34.0,
      -45.0,
      10.0,
      -23.0,
      65.0,
      10.0,
      -1.0,
      10.0,
      10.0,
      32.0,
      -1.0,
      -1.0,
      32.0,
      -67.0,
      10.0,
      32.0,
      43.0,
      21.0,
      21.0,
      -56.0,
      -45.0,
      -45.0,
      -56.0,
      -12.0,
      -34.0,
      32.0,
      76.0,
      -1.0,
      21.0,
      43.0,
      65.0,
      65.0,
      10.0,
      65.0,
      -34.0,
      -12.0,
      21.0,
      54.0,
      26.0,
      -23.0,
      21.0,
      10.0,
      -67.0
    ],
    "episode_lengths": [
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76
    ]
  },
  "sampler_perf": {
    "mean_raw_obs_processing_ms": 0.18698310904380072,
    "mean_inference_ms": 9.267812751512055,
    "mean_action_processing_ms": 0.07771383237859038,
    "mean_env_wait_ms": 0.03659776078961663,
    "mean_env_render_ms": 0.0
  },
  "num_faulty_episodes": 0,
  "connector_metrics": {
    "ObsPreprocessorConnector_ms": 0.004250288009643555,
    "StateBufferConnector_ms": 0.002818584442138672,
    "ViewRequirementAgentConnector_ms": 0.08105182647705078
  },
  "num_healthy_workers": 1,
  "num_in_flight_async_reqs": 0,
  "num_remote_worker_restarts": 0,
  "num_agent_steps_sampled": 36000,
  "num_agent_steps_trained": 36000,
  "num_env_steps_sampled": 36000,
  "num_env_steps_trained": 36000,
  "num_env_steps_sampled_this_iter": 4000,
  "num_env_steps_trained_this_iter": 4000,
  "timesteps_total": 36000,
  "num_steps_trained_this_iter": 4000,
  "agent_timesteps_total": 36000,
  "timers": {
    "training_iteration_time_ms": 71487.289,
    "sample_time_ms": 38305.523,
    "learn_time_ms": 33174.193,
    "learn_throughput": 120.576,
    "synch_weights_time_ms": 6.881
  },
  "counters": {
    "num_env_steps_sampled": 36000,
    "num_env_steps_trained": 36000,
    "num_agent_steps_sampled": 36000,
    "num_agent_steps_trained": 36000
  },
  "done": false,
  "episodes_total": 473,
  "training_iteration": 9,
  "trial_id": "b0a0c_00000",
  "date": "2023-05-31_15-55-10",
  "timestamp": 1685537710,
  "time_this_iter_s": 77.80091595649719,
  "time_total_s": 708.8194379806519,
  "pid": 48728,
  "hostname": "Ozans-MacBook-Pro.local",
  "node_ip": "127.0.0.1",
  "config": {
    "extra_python_environs_for_driver": {},
    "extra_python_environs_for_worker": {},
    "num_gpus": 0,
    "num_cpus_per_worker": 1,
    "num_gpus_per_worker": 0,
    "_fake_gpus": false,
    "num_learner_workers": 0,
    "num_gpus_per_learner_worker": 0,
    "num_cpus_per_learner_worker": 1,
    "local_gpu_idx": 0,
    "custom_resources_per_worker": {},
    "placement_strategy": "PACK",
    "eager_tracing": false,
    "eager_max_retraces": 20,
    "tf_session_args": {
      "intra_op_parallelism_threads": 2,
      "inter_op_parallelism_threads": 2,
      "gpu_options": {
        "allow_growth": true
      },
      "log_device_placement": false,
      "device_count": {
        "CPU": 1
      },
      "allow_soft_placement": true
    },
    "local_tf_session_args": {
      "intra_op_parallelism_threads": 8,
      "inter_op_parallelism_threads": 8
    },
    "env": "Supermarket",
    "env_config": {},
    "observation_space": null,
    "action_space": null,
    "env_task_fn": null,
    "render_env": false,
    "clip_rewards": null,
    "normalize_actions": true,
    "clip_actions": false,
    "disable_env_checking": false,
    "is_atari": false,
    "auto_wrap_old_gym_envs": true,
    "num_envs_per_worker": 1,
    "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>",
    "sample_async": false,
    "enable_connectors": true,
    "rollout_fragment_length": "auto",
    "batch_mode": "truncate_episodes",
    "remote_worker_envs": false,
    "remote_env_batch_wait_ms": 0,
    "validate_workers_after_construction": true,
    "preprocessor_pref": "deepmind",
    "observation_filter": "NoFilter",
    "synchronize_filters": true,
    "compress_observations": false,
    "enable_tf1_exec_eagerly": false,
    "sampler_perf_stats_ema_coef": null,
    "gamma": 0.9,
    "lr": 0.001,
    "train_batch_size": 4000,
    "model": {
      "_disable_preprocessor_api": false,
      "_disable_action_flattening": false,
      "fcnet_hiddens": [
        4,
        4
      ],
      "fcnet_activation": "tanh",
      "conv_filters": null,
      "conv_activation": "relu",
      "post_fcnet_hiddens": [],
      "post_fcnet_activation": "relu",
      "free_log_std": false,
      "no_final_linear": false,
      "vf_share_layers": false,
      "use_lstm": false,
      "max_seq_len": 20,
      "lstm_cell_size": 256,
      "lstm_use_prev_action": false,
      "lstm_use_prev_reward": false,
      "_time_major": false,
      "use_attention": false,
      "attention_num_transformer_units": 1,
      "attention_dim": 64,
      "attention_num_heads": 1,
      "attention_head_dim": 32,
      "attention_memory_inference": 50,
      "attention_memory_training": 50,
      "attention_position_wise_mlp_dim": 32,
      "attention_init_gru_gate_bias": 2.0,
      "attention_use_n_prev_actions": 0,
      "attention_use_n_prev_rewards": 0,
      "framestack": true,
      "dim": 84,
      "grayscale": false,
      "zero_mean": true,
      "custom_model": null,
      "custom_model_config": {},
      "custom_action_dist": null,
      "custom_preprocessor": null,
      "encoder_latent_dim": null,
      "lstm_use_prev_action_reward": -1,
      "_use_default_native_models": -1
    },
    "optimizer": {},
    "max_requests_in_flight_per_sampler_worker": 2,
    "learner_class": null,
    "_enable_learner_api": false,
    "_learner_hps": "PPOLearnerHPs(kl_coeff=0.2, kl_target=0.01, use_critic=True, clip_param=0.3, vf_clip_param=10.0, entropy_coeff=0.0, vf_loss_coeff=1.0, lr_schedule=None, entropy_coeff_schedule=None)",
    "explore": true,
    "exploration_config": {
      "type": "StochasticSampling"
    },
    "policy_states_are_swappable": false,
    "input_config": {},
    "actions_in_input_normalized": false,
    "postprocess_inputs": false,
    "shuffle_buffer_size": 0,
    "output": null,
    "output_config": {},
    "output_compress_columns": [
      "obs",
      "new_obs"
    ],
    "output_max_file_size": 67108864,
    "offline_sampling": false,
    "evaluation_interval": 1,
    "evaluation_duration": 10,
    "evaluation_duration_unit": "episodes",
    "evaluation_sample_timeout_s": 180.0,
    "evaluation_parallel_to_training": false,
    "evaluation_config": null,
    "off_policy_estimation_methods": {},
    "ope_split_batch_by_episode": true,
    "evaluation_num_workers": 1,
    "always_attach_evaluation_results": false,
    "enable_async_evaluation": false,
    "in_evaluation": false,
    "sync_filters_on_rollout_workers_timeout_s": 60.0,
    "keep_per_episode_custom_metrics": false,
    "metrics_episode_collection_timeout_s": 60.0,
    "metrics_num_episodes_for_smoothing": 100,
    "min_time_s_per_iteration": null,
    "min_train_timesteps_per_iteration": 0,
    "min_sample_timesteps_per_iteration": 0,
    "export_native_model_files": false,
    "checkpoint_trainable_policies_only": false,
    "logger_creator": null,
    "logger_config": null,
    "log_level": "WARN",
    "log_sys_usage": true,
    "fake_sampler": false,
    "seed": null,
    "worker_cls": null,
    "ignore_worker_failures": false,
    "recreate_failed_workers": false,
    "max_num_worker_restarts": 1000,
    "delay_between_worker_restarts_s": 60.0,
    "restart_failed_sub_environments": false,
    "num_consecutive_worker_failures_tolerance": 100,
    "worker_health_probe_timeout_s": 60,
    "worker_restore_timeout_s": 1800,
    "rl_module_spec": null,
    "_enable_rl_module_api": false,
    "_validate_exploration_conf_and_rl_modules": true,
    "_tf_policy_handles_more_than_one_loss": false,
    "_disable_preprocessor_api": false,
    "_disable_action_flattening": false,
    "_disable_execution_plan_api": true,
    "simple_optimizer": true,
    "replay_sequence_length": null,
    "horizon": -1,
    "soft_horizon": -1,
    "no_done_at_end": -1,
    "lr_schedule": null,
    "use_critic": true,
    "use_gae": true,
    "kl_coeff": 0.2,
    "sgd_minibatch_size": 128,
    "num_sgd_iter": 30,
    "shuffle_sequences": true,
    "vf_loss_coeff": 1.0,
    "entropy_coeff": 0.0,
    "entropy_coeff_schedule": null,
    "clip_param": 0.3,
    "vf_clip_param": 10.0,
    "grad_clip": null,
    "kl_target": 0.01,
    "vf_share_layers": -1,
    "__stdout_file__": null,
    "__stderr_file__": null,
    "lambda": 1.0,
    "input": "sampler",
    "multiagent": {
      "policies": {
        "default_policy": [
          null,
          null,
          null,
          null
        ]
      },
      "policy_mapping_fn": "<function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x28f7c7ac0>",
      "policies_to_train": null,
      "policy_map_capacity": 100,
      "policy_map_cache": -1,
      "count_steps_by": "env_steps",
      "observation_fn": null
    },
    "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>",
    "create_env_on_driver": false,
    "custom_eval_function": null,
    "framework": "tf2",
    "num_cpus_for_driver": 1,
    "num_workers": 1
  },
  "time_since_restore": 708.8194379806519,
  "iterations_since_restore": 9,
  "perf": {
    "cpu_util_percent": 42.812844036697236,
    "ram_util_percent": 72.17064220183487
  }
}
{
  "evaluation": {
    "episode_reward_max": 76.0,
    "episode_reward_min": -12.0,
    "episode_reward_mean": 34.2,
    "episode_len_mean": 76.0,
    "episode_media": {},
    "episodes_this_iter": 10,
    "policy_reward_min": {},
    "policy_reward_max": {},
    "policy_reward_mean": {},
    "custom_metrics": {},
    "hist_stats": {
      "episode_reward": [
        43.0,
        32.0,
        21.0,
        21.0,
        -12.0,
        65.0,
        10.0,
        54.0,
        76.0,
        32.0
      ],
      "episode_lengths": [
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76
      ]
    },
    "sampler_perf": {
      "mean_raw_obs_processing_ms": 0.1712119856910821,
      "mean_inference_ms": 9.207349124040718,
      "mean_action_processing_ms": 0.07681250023286666,
      "mean_env_wait_ms": 0.038155033908036484,
      "mean_env_render_ms": 0.0
    },
    "num_faulty_episodes": 0,
    "connector_metrics": {
      "ObsPreprocessorConnector_ms": 0.004789829254150391,
      "StateBufferConnector_ms": 0.0024771690368652344,
      "ViewRequirementAgentConnector_ms": 0.0805807113647461
    },
    "num_agent_steps_sampled_this_iter": 760,
    "num_env_steps_sampled_this_iter": 760,
    "timesteps_this_iter": 760,
    "num_healthy_workers": 1,
    "num_in_flight_async_reqs": 0,
    "num_remote_worker_restarts": 0
  },
  "custom_metrics": {},
  "episode_media": {},
  "info": {
    "learner": {
      "default_policy": {
        "learner_stats": {
          "cur_kl_coeff": 0.44999998807907104,
          "cur_lr": 0.0010000000474974513,
          "total_loss": 7.304342746734619,
          "policy_loss": -0.013784980401396751,
          "vf_loss": 7.312036991119385,
          "vf_explained_var": 0.0027185564395040274,
          "kl": 0.013533898629248142,
          "entropy": 2.8157010078430176,
          "entropy_coeff": 0.0
        },
        "custom_metrics": {},
        "num_agent_steps_trained": 125.0,
        "num_grad_updates_lifetime": 9120.5,
        "diff_num_grad_updates_vs_sampler_policy": 479.5
      }
    },
    "num_env_steps_sampled": 40000,
    "num_env_steps_trained": 40000,
    "num_agent_steps_sampled": 40000,
    "num_agent_steps_trained": 40000
  },
  "sampler_results": {
    "episode_reward_max": 76.0,
    "episode_reward_min": -100.0,
    "episode_reward_mean": 3.01,
    "episode_len_mean": 76.0,
    "episode_media": {},
    "episodes_this_iter": 53,
    "policy_reward_min": {},
    "policy_reward_max": {},
    "policy_reward_mean": {},
    "custom_metrics": {},
    "hist_stats": {
      "episode_reward": [
        21.0,
        -12.0,
        -12.0,
        43.0,
        -34.0,
        -45.0,
        10.0,
        -23.0,
        65.0,
        10.0,
        -1.0,
        10.0,
        10.0,
        32.0,
        -1.0,
        -1.0,
        32.0,
        -67.0,
        10.0,
        32.0,
        43.0,
        21.0,
        21.0,
        -56.0,
        -45.0,
        -45.0,
        -56.0,
        -12.0,
        -34.0,
        32.0,
        76.0,
        -1.0,
        21.0,
        43.0,
        65.0,
        65.0,
        10.0,
        65.0,
        -34.0,
        -12.0,
        21.0,
        54.0,
        26.0,
        -23.0,
        21.0,
        10.0,
        -67.0,
        -23.0,
        -67.0,
        -23.0,
        -12.0,
        -12.0,
        43.0,
        -23.0,
        32.0,
        10.0,
        -34.0,
        -34.0,
        -34.0,
        -23.0,
        -34.0,
        10.0,
        -12.0,
        -23.0,
        32.0,
        -67.0,
        10.0,
        54.0,
        65.0,
        54.0,
        54.0,
        54.0,
        65.0,
        32.0,
        32.0,
        10.0,
        -100.0,
        -34.0,
        54.0,
        10.0,
        -23.0,
        10.0,
        -1.0,
        65.0,
        65.0,
        21.0,
        -45.0,
        -67.0,
        -56.0,
        -45.0,
        -34.0,
        54.0,
        32.0,
        -1.0,
        10.0,
        -67.0,
        -23.0,
        10.0,
        65.0,
        -23.0
      ],
      "episode_lengths": [
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76,
        76
      ]
    },
    "sampler_perf": {
      "mean_raw_obs_processing_ms": 0.18695010158669276,
      "mean_inference_ms": 9.262543818931412,
      "mean_action_processing_ms": 0.07773907675565012,
      "mean_env_wait_ms": 0.03656296768932539,
      "mean_env_render_ms": 0.0
    },
    "num_faulty_episodes": 0,
    "connector_metrics": {
      "ObsPreprocessorConnector_ms": 0.004369974136352539,
      "StateBufferConnector_ms": 0.0028443336486816406,
      "ViewRequirementAgentConnector_ms": 0.08341002464294434
    }
  },
  "episode_reward_max": 76.0,
  "episode_reward_min": -100.0,
  "episode_reward_mean": 3.01,
  "episode_len_mean": 76.0,
  "episodes_this_iter": 53,
  "policy_reward_min": {},
  "policy_reward_max": {},
  "policy_reward_mean": {},
  "hist_stats": {
    "episode_reward": [
      21.0,
      -12.0,
      -12.0,
      43.0,
      -34.0,
      -45.0,
      10.0,
      -23.0,
      65.0,
      10.0,
      -1.0,
      10.0,
      10.0,
      32.0,
      -1.0,
      -1.0,
      32.0,
      -67.0,
      10.0,
      32.0,
      43.0,
      21.0,
      21.0,
      -56.0,
      -45.0,
      -45.0,
      -56.0,
      -12.0,
      -34.0,
      32.0,
      76.0,
      -1.0,
      21.0,
      43.0,
      65.0,
      65.0,
      10.0,
      65.0,
      -34.0,
      -12.0,
      21.0,
      54.0,
      26.0,
      -23.0,
      21.0,
      10.0,
      -67.0,
      -23.0,
      -67.0,
      -23.0,
      -12.0,
      -12.0,
      43.0,
      -23.0,
      32.0,
      10.0,
      -34.0,
      -34.0,
      -34.0,
      -23.0,
      -34.0,
      10.0,
      -12.0,
      -23.0,
      32.0,
      -67.0,
      10.0,
      54.0,
      65.0,
      54.0,
      54.0,
      54.0,
      65.0,
      32.0,
      32.0,
      10.0,
      -100.0,
      -34.0,
      54.0,
      10.0,
      -23.0,
      10.0,
      -1.0,
      65.0,
      65.0,
      21.0,
      -45.0,
      -67.0,
      -56.0,
      -45.0,
      -34.0,
      54.0,
      32.0,
      -1.0,
      10.0,
      -67.0,
      -23.0,
      10.0,
      65.0,
      -23.0
    ],
    "episode_lengths": [
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76,
      76
    ]
  },
  "sampler_perf": {
    "mean_raw_obs_processing_ms": 0.18695010158669276,
    "mean_inference_ms": 9.262543818931412,
    "mean_action_processing_ms": 0.07773907675565012,
    "mean_env_wait_ms": 0.03656296768932539,
    "mean_env_render_ms": 0.0
  },
  "num_faulty_episodes": 0,
  "connector_metrics": {
    "ObsPreprocessorConnector_ms": 0.004369974136352539,
    "StateBufferConnector_ms": 0.0028443336486816406,
    "ViewRequirementAgentConnector_ms": 0.08341002464294434
  },
  "num_healthy_workers": 1,
  "num_in_flight_async_reqs": 0,
  "num_remote_worker_restarts": 0,
  "num_agent_steps_sampled": 40000,
  "num_agent_steps_trained": 40000,
  "num_env_steps_sampled": 40000,
  "num_env_steps_trained": 40000,
  "num_env_steps_sampled_this_iter": 4000,
  "num_env_steps_trained_this_iter": 4000,
  "timesteps_total": 40000,
  "num_steps_trained_this_iter": 4000,
  "agent_timesteps_total": 40000,
  "timers": {
    "training_iteration_time_ms": 71380.965,
    "sample_time_ms": 38284.231,
    "learn_time_ms": 33089.235,
    "learn_throughput": 120.885,
    "synch_weights_time_ms": 6.827
  },
  "counters": {
    "num_env_steps_sampled": 40000,
    "num_env_steps_trained": 40000,
    "num_agent_steps_sampled": 40000,
    "num_agent_steps_trained": 40000
  },
  "done": true,
  "episodes_total": 526,
  "training_iteration": 10,
  "trial_id": "b0a0c_00000",
  "date": "2023-05-31_15-56-28",
  "timestamp": 1685537788,
  "time_this_iter_s": 77.63278293609619,
  "time_total_s": 786.452220916748,
  "pid": 48728,
  "hostname": "Ozans-MacBook-Pro.local",
  "node_ip": "127.0.0.1",
  "config": {
    "extra_python_environs_for_driver": {},
    "extra_python_environs_for_worker": {},
    "num_gpus": 0,
    "num_cpus_per_worker": 1,
    "num_gpus_per_worker": 0,
    "_fake_gpus": false,
    "num_learner_workers": 0,
    "num_gpus_per_learner_worker": 0,
    "num_cpus_per_learner_worker": 1,
    "local_gpu_idx": 0,
    "custom_resources_per_worker": {},
    "placement_strategy": "PACK",
    "eager_tracing": false,
    "eager_max_retraces": 20,
    "tf_session_args": {
      "intra_op_parallelism_threads": 2,
      "inter_op_parallelism_threads": 2,
      "gpu_options": {
        "allow_growth": true
      },
      "log_device_placement": false,
      "device_count": {
        "CPU": 1
      },
      "allow_soft_placement": true
    },
    "local_tf_session_args": {
      "intra_op_parallelism_threads": 8,
      "inter_op_parallelism_threads": 8
    },
    "env": "Supermarket",
    "env_config": {},
    "observation_space": null,
    "action_space": null,
    "env_task_fn": null,
    "render_env": false,
    "clip_rewards": null,
    "normalize_actions": true,
    "clip_actions": false,
    "disable_env_checking": false,
    "is_atari": false,
    "auto_wrap_old_gym_envs": true,
    "num_envs_per_worker": 1,
    "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>",
    "sample_async": false,
    "enable_connectors": true,
    "rollout_fragment_length": "auto",
    "batch_mode": "truncate_episodes",
    "remote_worker_envs": false,
    "remote_env_batch_wait_ms": 0,
    "validate_workers_after_construction": true,
    "preprocessor_pref": "deepmind",
    "observation_filter": "NoFilter",
    "synchronize_filters": true,
    "compress_observations": false,
    "enable_tf1_exec_eagerly": false,
    "sampler_perf_stats_ema_coef": null,
    "gamma": 0.9,
    "lr": 0.001,
    "train_batch_size": 4000,
    "model": {
      "_disable_preprocessor_api": false,
      "_disable_action_flattening": false,
      "fcnet_hiddens": [
        4,
        4
      ],
      "fcnet_activation": "tanh",
      "conv_filters": null,
      "conv_activation": "relu",
      "post_fcnet_hiddens": [],
      "post_fcnet_activation": "relu",
      "free_log_std": false,
      "no_final_linear": false,
      "vf_share_layers": false,
      "use_lstm": false,
      "max_seq_len": 20,
      "lstm_cell_size": 256,
      "lstm_use_prev_action": false,
      "lstm_use_prev_reward": false,
      "_time_major": false,
      "use_attention": false,
      "attention_num_transformer_units": 1,
      "attention_dim": 64,
      "attention_num_heads": 1,
      "attention_head_dim": 32,
      "attention_memory_inference": 50,
      "attention_memory_training": 50,
      "attention_position_wise_mlp_dim": 32,
      "attention_init_gru_gate_bias": 2.0,
      "attention_use_n_prev_actions": 0,
      "attention_use_n_prev_rewards": 0,
      "framestack": true,
      "dim": 84,
      "grayscale": false,
      "zero_mean": true,
      "custom_model": null,
      "custom_model_config": {},
      "custom_action_dist": null,
      "custom_preprocessor": null,
      "encoder_latent_dim": null,
      "lstm_use_prev_action_reward": -1,
      "_use_default_native_models": -1
    },
    "optimizer": {},
    "max_requests_in_flight_per_sampler_worker": 2,
    "learner_class": null,
    "_enable_learner_api": false,
    "_learner_hps": "PPOLearnerHPs(kl_coeff=0.2, kl_target=0.01, use_critic=True, clip_param=0.3, vf_clip_param=10.0, entropy_coeff=0.0, vf_loss_coeff=1.0, lr_schedule=None, entropy_coeff_schedule=None)",
    "explore": true,
    "exploration_config": {
      "type": "StochasticSampling"
    },
    "policy_states_are_swappable": false,
    "input_config": {},
    "actions_in_input_normalized": false,
    "postprocess_inputs": false,
    "shuffle_buffer_size": 0,
    "output": null,
    "output_config": {},
    "output_compress_columns": [
      "obs",
      "new_obs"
    ],
    "output_max_file_size": 67108864,
    "offline_sampling": false,
    "evaluation_interval": 1,
    "evaluation_duration": 10,
    "evaluation_duration_unit": "episodes",
    "evaluation_sample_timeout_s": 180.0,
    "evaluation_parallel_to_training": false,
    "evaluation_config": null,
    "off_policy_estimation_methods": {},
    "ope_split_batch_by_episode": true,
    "evaluation_num_workers": 1,
    "always_attach_evaluation_results": false,
    "enable_async_evaluation": false,
    "in_evaluation": false,
    "sync_filters_on_rollout_workers_timeout_s": 60.0,
    "keep_per_episode_custom_metrics": false,
    "metrics_episode_collection_timeout_s": 60.0,
    "metrics_num_episodes_for_smoothing": 100,
    "min_time_s_per_iteration": null,
    "min_train_timesteps_per_iteration": 0,
    "min_sample_timesteps_per_iteration": 0,
    "export_native_model_files": false,
    "checkpoint_trainable_policies_only": false,
    "logger_creator": null,
    "logger_config": null,
    "log_level": "WARN",
    "log_sys_usage": true,
    "fake_sampler": false,
    "seed": null,
    "worker_cls": null,
    "ignore_worker_failures": false,
    "recreate_failed_workers": false,
    "max_num_worker_restarts": 1000,
    "delay_between_worker_restarts_s": 60.0,
    "restart_failed_sub_environments": false,
    "num_consecutive_worker_failures_tolerance": 100,
    "worker_health_probe_timeout_s": 60,
    "worker_restore_timeout_s": 1800,
    "rl_module_spec": null,
    "_enable_rl_module_api": false,
    "_validate_exploration_conf_and_rl_modules": true,
    "_tf_policy_handles_more_than_one_loss": false,
    "_disable_preprocessor_api": false,
    "_disable_action_flattening": false,
    "_disable_execution_plan_api": true,
    "simple_optimizer": true,
    "replay_sequence_length": null,
    "horizon": -1,
    "soft_horizon": -1,
    "no_done_at_end": -1,
    "lr_schedule": null,
    "use_critic": true,
    "use_gae": true,
    "kl_coeff": 0.2,
    "sgd_minibatch_size": 128,
    "num_sgd_iter": 30,
    "shuffle_sequences": true,
    "vf_loss_coeff": 1.0,
    "entropy_coeff": 0.0,
    "entropy_coeff_schedule": null,
    "clip_param": 0.3,
    "vf_clip_param": 10.0,
    "grad_clip": null,
    "kl_target": 0.01,
    "vf_share_layers": -1,
    "__stdout_file__": null,
    "__stderr_file__": null,
    "lambda": 1.0,
    "input": "sampler",
    "multiagent": {
      "policies": {
        "default_policy": [
          null,
          null,
          null,
          null
        ]
      },
      "policy_mapping_fn": "<function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x28f7c7ac0>",
      "policies_to_train": null,
      "policy_map_capacity": 100,
      "policy_map_cache": -1,
      "count_steps_by": "env_steps",
      "observation_fn": null
    },
    "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>",
    "create_env_on_driver": false,
    "custom_eval_function": null,
    "framework": "tf2",
    "num_cpus_for_driver": 1,
    "num_workers": 1
  },
  "time_since_restore": 786.452220916748,
  "iterations_since_restore": 10,
  "perf": {
    "cpu_util_percent": 42.03148148148149,
    "ram_util_percent": 72.21111111111112
  }
}
